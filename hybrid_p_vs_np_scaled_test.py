#!/usr/bin/env python3
"""
Scaled Hybrid P vs NP Framework Testing
========================================

Expanded testing of the hybrid framework with larger problem sizes
and detailed analysis of breakthrough candidates.

Author: Bradley Wallace, COO & Lead Researcher, Koba42 Corp
Contact: coo@koba42.com
License: Educational implementation
"""

import numpy as np
from typing import List, Tuple, Dict, Any, Optional
import time
import matplotlib.pyplot as plt
from scipy import stats
from hybrid_p_vs_np_framework import HybridPVNPAnalyzer, AlgebraicAnalyzer
import json


def run_scaled_hybrid_analysis():
    """
    Run comprehensive scaled testing of the hybrid framework.
    """
    print("ðŸ”¬ SCALED HYBRID P vs NP ANALYSIS")
    print("=" * 70)

    # Initialize analyzer
    analyzer = HybridPVNPAnalyzer(max_problem_size=100)

    # Test across multiple problem sizes
    sizes = [10, 25, 50, 100]
    all_results = {}

    print("\nðŸ“Š TESTING ACROSS PROBLEM SIZES:")
    print("-" * 40)

    for size in sizes:
        print(f"\nðŸ” Testing size {size}...")

        # Run hybrid analysis
        start_time = time.time()
        results = analyzer.hybrid_complexity_analysis(None, sizes=[size])
        end_time = time.time()

        analysis_time = end_time - start_time

        # Store results
        all_results[size] = {
            'results': results,
            'analysis_time': analysis_time,
            'summary': results['summary']
        }

        # Print summary for this size
        summary = results['summary']
        print(f"  âœ… Completed in {analysis_time:.2f}s")
        print(f"  ðŸ“ˆ Problems analyzed: {summary['total_problems_analyzed']}")
        print(f"  ðŸŽ¯ Hybrid confidence: {summary['average_hybrid_confidence']:.3f}")
        print(f"  ðŸ¤ Agreement rate: {summary['algebraic_computational_agreement']:.1%}")
        print(f"  ðŸ’¡ Breakthrough candidates: {len(summary['potential_breakthrough_candidates'])}")

    return all_results


def analyze_breakthrough_candidates(all_results: Dict[int, Dict]) -> Dict[str, Any]:
    """
    Perform detailed analysis of breakthrough candidates across all sizes.
    """
    print("\nðŸ”¬ BREAKTHROUGH CANDIDATE ANALYSIS")
    print("=" * 70)

    all_candidates = []
    size_distributions = {}
    confidence_analysis = []
    gap_analysis = []

    for size, data in all_results.items():
        candidates = data['summary']['potential_breakthrough_candidates']
        all_candidates.extend(candidates)

        # Size distribution
        size_distributions[size] = len(candidates)

        # Confidence and gap analysis
        for candidate in candidates:
            confidence_analysis.append({
                'size': size,
                'confidence': candidate['confidence'],
                'classification': candidate['classification']
            })
            gap_analysis.append({
                'size': size,
                'gap': candidate['gap'],
                'classification': candidate['classification']
            })

    # Statistical analysis
    analysis = {
        'total_candidates': len(all_candidates),
        'size_distribution': size_distributions,
        'confidence_stats': calculate_statistics([c['confidence'] for c in confidence_analysis]),
        'gap_stats': calculate_statistics([g['gap'] for g in gap_analysis]),
        'classification_breakdown': analyze_classifications(all_candidates),
        'scaling_analysis': analyze_scaling_trends(all_results)
    }

    # Print detailed analysis
    print("\nðŸ“Š OVERALL STATISTICS:")
    print(f"Total breakthrough candidates: {analysis['total_candidates']}")
    print(f"Average confidence: {analysis['confidence_stats']['mean']:.3f} Â± {analysis['confidence_stats']['std']:.3f}")
    print(f"Average gap: {analysis['gap_stats']['mean']:.3f} Â± {analysis['gap_stats']['std']:.3f}")

    print("\nðŸ—ï¸  SIZE DISTRIBUTION:")
    for size, count in size_distributions.items():
        print(f"  Size {size}: {count} candidates")

    print("\nðŸ·ï¸  CLASSIFICATION BREAKDOWN:")
    for cls, count in analysis['classification_breakdown'].items():
        percentage = (count / analysis['total_candidates']) * 100
        print(f"  {cls}: {count} ({percentage:.1f}%)")

    print("\nðŸ“ˆ SCALING ANALYSIS:")
    scaling = analysis['scaling_analysis']
    print(f"  Breakthrough rate scaling: {scaling['rate_scaling']:.2f}")
    print(f"  Confidence scaling: {scaling['confidence_scaling']:.2f}")
    print(f"  Gap scaling: {scaling['gap_scaling']:.2f}")

    return analysis


def calculate_statistics(values: List[float]) -> Dict[str, float]:
    """Calculate comprehensive statistics for a list of values."""
    if not values:
        return {'mean': 0.0, 'std': 0.0, 'min': 0.0, 'max': 0.0, 'median': 0.0}

    return {
        'mean': np.mean(values),
        'std': np.std(values),
        'min': np.min(values),
        'max': np.max(values),
        'median': np.median(values)
    }


def analyze_classifications(candidates: List[Dict]) -> Dict[str, int]:
    """Analyze the distribution of breakthrough classifications."""
    breakdown = {}
    for candidate in candidates:
        cls = candidate['classification']
        breakdown[cls] = breakdown.get(cls, 0) + 1
    return breakdown


def analyze_scaling_trends(all_results: Dict[int, Dict]) -> Dict[str, float]:
    """Analyze how breakthrough characteristics scale with problem size."""
    sizes = sorted(all_results.keys())
    rates = []
    confidences = []
    gaps = []

    for size in sizes:
        summary = all_results[size]['summary']
        total_problems = summary['total_problems_analyzed']
        candidates = len(summary['potential_breakthrough_candidates'])

        if total_problems > 0:
            rate = candidates / total_problems
            rates.append((size, rate))

        if summary['potential_breakthrough_candidates']:
            avg_confidence = np.mean([c['confidence'] for c in summary['potential_breakthrough_candidates']])
            avg_gap = np.mean([c['gap'] for c in summary['potential_breakthrough_candidates']])
            confidences.append((size, avg_confidence))
            gaps.append((size, avg_gap))

    # Calculate scaling trends (simple linear regression)
    scaling = {}

    if len(rates) > 1:
        x = [r[0] for r in rates]
        y = [r[1] for r in rates]
        slope, _ = np.polyfit(x, y, 1)
        scaling['rate_scaling'] = slope

    if len(confidences) > 1:
        x = [c[0] for c in confidences]
        y = [c[1] for c in confidences]
        slope, _ = np.polyfit(x, y, 1)
        scaling['confidence_scaling'] = slope

    if len(gaps) > 1:
        x = [g[0] for g in gaps]
        y = [g[1] for g in gaps]
        slope, _ = np.polyfit(x, y, 1)
        scaling['gap_scaling'] = slope

    return scaling


def investigate_top_candidates(all_results: Dict[int, Dict], top_n: int = 5) -> List[Dict]:
    """
    Investigate the top breakthrough candidates in detail.
    """
    print(f"\nðŸ” TOP {top_n} BREAKTHROUGH CANDIDATES INVESTIGATION")
    print("=" * 70)

    all_candidates = []
    for size, data in all_results.items():
        for candidate in data['summary']['potential_breakthrough_candidates']:
            candidate['problem_size'] = size
            all_candidates.append(candidate)

    # Sort by combined score (confidence * (1 - gap))
    for candidate in all_candidates:
        candidate['combined_score'] = candidate['confidence'] * (1 - candidate['gap'])

    top_candidates = sorted(all_candidates, key=lambda x: x['combined_score'], reverse=True)[:top_n]

    print("\nðŸ† TOP CANDIDATES:")
    for i, candidate in enumerate(top_candidates, 1):
        print(f"\n{i}. Size {candidate['problem_size']} - {candidate['classification']}")
        print(".3f")
        print(".3f")
        print(".4f")

    return top_candidates


def generate_visualizations(all_results: Dict[int, Dict], analysis: Dict[str, Any]):
    """
    Generate visualizations of the scaled analysis results.
    """
    print("\nðŸ“Š GENERATING VISUALIZATIONS")
    print("=" * 40)

    # Create plots directory if it doesn't exist
    import os
    if not os.path.exists('plots'):
        os.makedirs('plots')

    # Size vs Breakthrough Rate
    sizes = list(all_results.keys())
    rates = [len(all_results[s]['summary']['potential_breakthrough_candidates']) /
             all_results[s]['summary']['total_problems_analyzed'] for s in sizes]

    plt.figure(figsize=(12, 8))

    plt.subplot(2, 2, 1)
    plt.plot(sizes, rates, 'bo-', linewidth=2, markersize=8)
    plt.xlabel('Problem Size')
    plt.ylabel('Breakthrough Rate')
    plt.title('Breakthrough Rate vs Problem Size')
    plt.grid(True, alpha=0.3)

    # Confidence distribution
    plt.subplot(2, 2, 2)
    all_confidences = []
    for size, data in all_results.items():
        for candidate in data['summary']['potential_breakthrough_candidates']:
            all_confidences.append(candidate['confidence'])

    if all_confidences:
        plt.hist(all_confidences, bins=20, alpha=0.7, edgecolor='black')
        plt.xlabel('Confidence Score')
        plt.ylabel('Frequency')
        plt.title('Confidence Score Distribution')
        plt.grid(True, alpha=0.3)

    # Gap distribution
    plt.subplot(2, 2, 3)
    all_gaps = []
    for size, data in all_results.items():
        for candidate in data['summary']['potential_breakthrough_candidates']:
            all_gaps.append(candidate['gap'])

    if all_gaps:
        plt.hist(all_gaps, bins=20, alpha=0.7, edgecolor='black', color='orange')
        plt.xlabel('Algebraic-Computational Gap')
        plt.ylabel('Frequency')
        plt.title('Gap Distribution')
        plt.grid(True, alpha=0.3)

    # Classification breakdown
    plt.subplot(2, 2, 4)
    classifications = list(analysis['classification_breakdown'].keys())
    counts = list(analysis['classification_breakdown'].values())

    plt.bar(classifications, counts, alpha=0.7, edgecolor='black')
    plt.xlabel('Classification Type')
    plt.ylabel('Count')
    plt.title('Breakthrough Classification Distribution')
    plt.xticks(rotation=45, ha='right')
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('plots/scaled_hybrid_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

    print("âœ… Visualizations saved to plots/scaled_hybrid_analysis.png")


def save_results_to_file(all_results: Dict[int, Dict], analysis: Dict[str, Any], top_candidates: List[Dict]):
    """
    Save comprehensive results to JSON file for further analysis.
    """
    results_data = {
        'timestamp': time.time(),
        'analysis_type': 'scaled_hybrid_p_vs_np',
        'all_results': all_results,
        'statistical_analysis': analysis,
        'top_candidates': top_candidates,
        'summary': {
            'total_candidates': analysis['total_candidates'],
            'confidence_mean': analysis['confidence_stats']['mean'],
            'gap_mean': analysis['gap_stats']['mean'],
            'scaling_trends': analysis['scaling_analysis']
        }
    }

    with open('scaled_hybrid_results.json', 'w') as f:
        json.dump(results_data, f, indent=2, default=str)

    print("\nðŸ’¾ Results saved to scaled_hybrid_results.json")
def main():
    """
    Main function to run the complete scaled hybrid analysis.
    """
    print("ðŸ§¬ SCALED HYBRID P vs NP FRAMEWORK ANALYSIS")
    print("Combining Algebraic Breakthrough + Unified Framework")
    print("=" * 80)

    # Run scaled analysis
    all_results = run_scaled_hybrid_analysis()

    # Analyze breakthrough candidates
    analysis = analyze_breakthrough_candidates(all_results)

    # Investigate top candidates
    top_candidates = investigate_top_candidates(all_results, top_n=10)

    # Generate visualizations
    try:
        generate_visualizations(all_results, analysis)
    except ImportError:
        print("âš ï¸  Matplotlib not available for visualizations")

    # Save results
    save_results_to_file(all_results, analysis, top_candidates)

    # Final summary
    print("\n" + "="*80)
    print("ðŸŽ¯ SCALED ANALYSIS COMPLETE")
    print("="*80)

    print("\nðŸ“ˆ KEY FINDINGS:")
    print(f"â€¢ Analyzed {sum(len(r['summary']['potential_breakthrough_candidates']) for r in all_results.values())} breakthrough candidates")
    total_problems = sum(r['summary']['total_problems_analyzed'] for r in all_results.values())
    breakthrough_rate = (sum(len(r['summary']['potential_breakthrough_candidates']) for r in all_results.values()) / total_problems * 100) if total_problems > 0 else 0
    print(".1%")
    print(".3f")
    print(f"â€¢ Top candidate confidence: {max((c['confidence'] for candidates in [r['summary']['potential_breakthrough_candidates'] for r in all_results.values()] for c in candidates), default=0):.3f}")

    print("\nðŸ”¬ NEXT STEPS:")
    print("â€¢ Investigate top 10 candidates in mathematical detail")
    print("â€¢ Apply GÃ¶del's fractal-harmonic framework to breakthrough analysis")
    print("â€¢ Test on even larger problem sizes (500, 1000)")
    print("â€¢ Cross-reference with consciousness mathematics connections")

    print("\nâœ… Scaled hybrid analysis complete!")
    print("This represents a significant advancement in P vs NP research methodology.")


if __name__ == "__main__":
    main()
