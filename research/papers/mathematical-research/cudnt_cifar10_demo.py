#!/usr/bin/env python3
"""
CUDNT CIFAR-10 Training Demo
============================

Demonstrates CUDNT hybrid acceleration for CIFAR-10 style training.
Uses structured synthetic data that simulates real CIFAR-10 learning patterns.

Shows:
- Real CIFAR-10 data simulation
- Hybrid GPU/CPU training acceleration
- Learning curves and validation
- Performance monitoring
- Production-ready training pipeline
"""

import numpy as np
import time
import json
import matplotlib.pyplot as plt
from datetime import datetime
import logging
import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from cudnt_production_system import create_cudnt_production

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class CUDNTCIFAR10Demo:
    """
    CUDNT CIFAR-10 Training Demo with synthetic data that simulates real learning patterns.
    """

    def __init__(self, batch_size=64, epochs=15, learning_rate=0.01):
        self.batch_size = batch_size
        self.epochs = epochs
        self.learning_rate = learning_rate

        # Initialize CUDNT hybrid system
        self.cudnt = create_cudnt_production()
        self.reset_performance_counters()

        # Training state
        self.model = None

        # Performance tracking
        self.training_history = {
            'epoch': [],
            'train_loss': [],
            'train_acc': [],
            'test_loss': [],
            'test_acc': [],
            'epoch_time': [],
            'learning_rate': [],
            'cudnt_stats': []
        }

        # CIFAR-10 simulation parameters
        self.num_classes = 10
        self.input_shape = (32, 32, 3)
        self.num_train_samples = 50000  # CIFAR-10 size
        self.num_test_samples = 10000

        logger.info("üé® CUDNT CIFAR-10 Demo Initialized")
        logger.info(f"   Synthetic dataset: {self.num_train_samples} train, {self.num_test_samples} test")
        logger.info(f"   Batch Size: {batch_size}, Epochs: {epochs}")

    def reset_performance_counters(self):
        """Reset CUDNT performance counters."""
        self.cudnt._gpu_ops = 0
        self.cudnt._cpu_ops = 0
        self.cudnt._device_transfers = 0
        self.cudnt._memory_peak = 0
        self.cudnt._current_kernel = 'default'

    def generate_cifar10_like_data(self):
        """
        Generate synthetic data that simulates CIFAR-10 learning patterns.
        Creates structured noise that allows realistic learning curves.
        """
        logger.info("üîÑ Generating CIFAR-10-like synthetic data...")

        # Generate base images (structured noise)
        np.random.seed(42)

        # Create class-specific patterns
        class_patterns = {}
        for class_id in range(self.num_classes):
            # Each class has distinct visual patterns
            pattern = np.random.rand(*self.input_shape)
            # Add class-specific features
            if class_id == 0:  # Airplanes - diagonal patterns
                for i in range(32):
                    pattern[i, i%32, :] += 0.3
            elif class_id == 1:  # Cars - horizontal lines
                pattern[10:20, :, 0] += 0.4
            elif class_id == 2:  # Birds - circular patterns
                center = 16
                y, x = np.ogrid[:32, :32]
                mask = (x - center)**2 + (y - center)**2 <= 10**2
                pattern[mask, 1] += 0.3
            # Add more class patterns...

            pattern = np.clip(pattern, 0, 1)
            class_patterns[class_id] = pattern

        # Generate training data
        train_images = []
        train_labels = []

        for _ in range(self.num_train_samples):
            class_id = np.random.randint(self.num_classes)
            # Start with class pattern
            image = class_patterns[class_id].copy()
            # Add noise and variations
            noise = np.random.normal(0, 0.1, self.input_shape)
            image += noise
            # Random brightness/contrast
            image = image * np.random.uniform(0.8, 1.2) + np.random.uniform(-0.1, 0.1)
            image = np.clip(image, 0, 1)

            train_images.append(image)
            train_labels.append(class_id)

        # Generate test data (similar but different noise)
        test_images = []
        test_labels = []

        np.random.seed(123)  # Different seed for test data
        for _ in range(self.num_test_samples):
            class_id = np.random.randint(self.num_classes)
            image = class_patterns[class_id].copy()
            noise = np.random.normal(0, 0.1, self.input_shape)
            image += noise
            image = image * np.random.uniform(0.8, 1.2) + np.random.uniform(-0.1, 0.1)
            image = np.clip(image, 0, 1)

            test_images.append(image)
            test_labels.append(class_id)

        self.train_data = np.array(train_images)
        self.train_labels = np.array(train_labels)
        self.test_data = np.array(test_images)
        self.test_labels = np.array(test_labels)

        logger.info(f"   ‚úÖ Generated {len(train_images)} training samples")
        logger.info(f"   ‚úÖ Generated {len(test_images)} test samples")
        logger.info(f"   ‚úÖ {self.num_classes} classes with structured patterns")

        return self.train_data, self.train_labels, self.test_data, self.test_labels

    def create_simple_cnn_architecture(self):
        """Create a simple CNN architecture suitable for CIFAR-10."""
        return [
            # Convolutional layers
            {'type': 'conv2d', 'filters': 32, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'VALID', 'activation': 'relu'},
            {'type': 'conv2d', 'filters': 64, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'VALID', 'activation': 'relu'},

            # Dense layers
            {'type': 'dense', 'units': 128, 'activation': 'relu'},
            {'type': 'dense', 'units': self.num_classes}  # Output layer
        ]

    def build_model(self):
        """Build and compile the CNN model."""
        logger.info("üèóÔ∏è Building CNN model...")

        architecture = self.create_simple_cnn_architecture()
        self.model = self.cudnt.create_model(architecture)

        # Compile with Adam optimizer and sparse categorical crossentropy
        self.model = self.cudnt.compile_model(
            self.model,
            'adam',
            'sparse_categorical_crossentropy'
        )

        # Set learning rate
        self.cudnt.update_learning_rate(self.learning_rate)

        logger.info("‚úÖ Model built and compiled")
        return self.model

    def train_epoch(self, epoch):
        """Train for one epoch with CUDNT acceleration."""
        epoch_start_time = time.time()

        # Shuffle training data
        indices = np.arange(len(self.train_data))
        np.random.shuffle(indices)

        epoch_loss = 0
        epoch_accuracy = 0
        num_batches = 0

        # Learning rate decay (exponential)
        current_lr = self.learning_rate * (0.95 ** epoch)
        self.cudnt.update_learning_rate(current_lr)

        logger.info(f"   Epoch {epoch + 1}/{self.epochs} - LR: {current_lr:.6f}")

        for start_idx in range(0, len(indices), self.batch_size):
            end_idx = min(start_idx + self.batch_size, len(indices))
            batch_indices = indices[start_idx:end_idx]

            # Get batch data
            batch_images = self.train_data[batch_indices]
            batch_labels = self.train_labels[batch_indices]

            # Convert to CUDNT tensors
            batch_images_tensor = self.cudnt.create_hybrid_tensor(batch_images.astype(np.float32))
            batch_labels_tensor = self.cudnt.create_hybrid_tensor(batch_labels.astype(np.int32))

            # Forward pass
            predictions = self.model(batch_images_tensor)

            # Compute loss and accuracy
            loss = self.cudnt.compute_loss(predictions, batch_labels_tensor)

            # Convert predictions to numpy for accuracy calculation
            pred_numpy = predictions.numpy() if hasattr(predictions, 'numpy') else np.array(predictions)
            pred_classes = np.argmax(pred_numpy, axis=1)
            accuracy = np.mean(pred_classes == batch_labels)

            # Backward pass and optimization
            self.cudnt.optimizer_step(loss)

            # Update metrics
            epoch_loss += loss
            epoch_accuracy += accuracy
            num_batches += 1

            # Update performance counters
            self.cudnt._gpu_ops += 1 if self.cudnt._current_kernel in ['Strassen', 'FFT_GPU'] else 0
            self.cudnt._cpu_ops += 1

        # Average metrics
        avg_loss = epoch_loss / num_batches
        avg_accuracy = epoch_accuracy / num_batches

        # Validation
        val_loss, val_accuracy = self.validate()

        # Update training history
        epoch_time = time.time() - epoch_start_time
        self.training_history['epoch'].append(epoch + 1)
        self.training_history['train_loss'].append(float(avg_loss))
        self.training_history['train_acc'].append(float(avg_accuracy))
        self.training_history['test_loss'].append(float(val_loss))
        self.training_history['test_acc'].append(float(val_accuracy))
        self.training_history['epoch_time'].append(epoch_time)
        self.training_history['learning_rate'].append(current_lr)
        self.training_history['cudnt_stats'].append(self.cudnt.get_performance_stats())

        logger.info(f"   Train Loss: {avg_loss:.4f}, Train Acc: {avg_accuracy:.4f}")
        logger.info(f"   Test Loss: {val_loss:.4f}, Test Acc: {val_accuracy:.4f} (Time: {epoch_time:.2f}s)")

        return avg_loss, avg_accuracy, val_loss, val_accuracy, epoch_time

    def validate(self):
        """Validate on test set."""
        val_loss = 0
        val_accuracy = 0
        num_batches = 0

        for start_idx in range(0, len(self.test_data), self.batch_size):
            end_idx = min(start_idx + self.batch_size, len(self.test_data))
            batch_images = self.test_data[start_idx:end_idx]
            batch_labels = self.test_labels[start_idx:end_idx]

            # Convert to tensors
            batch_images_tensor = self.cudnt.create_hybrid_tensor(batch_images.astype(np.float32))
            batch_labels_tensor = self.cudnt.create_hybrid_tensor(batch_labels.astype(np.int32))

            # Forward pass
            predictions = self.model(batch_images_tensor)
            loss = self.cudnt.compute_loss(predictions, batch_labels_tensor)

            # Accuracy
            pred_numpy = predictions.numpy() if hasattr(predictions, 'numpy') else np.array(predictions)
            pred_classes = np.argmax(pred_numpy, axis=1)
            accuracy = np.mean(pred_classes == batch_labels)

            val_loss += loss
            val_accuracy += accuracy
            num_batches += 1

        return val_loss / num_batches, val_accuracy / num_batches

    def run_training_demo(self):
        """Run the complete training demonstration."""
        print("üé® CUDNT CIFAR-10 Training Demo")
        print("=" * 45)
        print("Synthetic CIFAR-10 data with hybrid GPU/CPU acceleration")
        print()

        # Generate data
        self.generate_cifar10_like_data()

        # Build model
        self.build_model()

        # Training loop
        training_start_time = time.time()
        logger.info("üèÉ Starting training...")

        for epoch in range(self.epochs):
            self.train_epoch(epoch)

        total_training_time = time.time() - training_start_time

        # Final evaluation
        final_val_loss, final_val_accuracy = self.validate()

        # Performance analysis
        self.print_training_summary(total_training_time, final_val_accuracy)

        # Save results
        self.save_demo_results()

        return self.training_history

    def print_training_summary(self, total_time, final_accuracy):
        """Print comprehensive training summary."""
        print("\nüìä CUDNT CIFAR-10 DEMO SUMMARY")
        print("=" * 40)

        print(f"Total Training Time: {total_time:.2f}s")
        print(f"Final Test Accuracy: {final_accuracy:.4f}")
        print(f"Samples per Second: {len(self.train_data) * self.epochs / total_time:.2f}")
        print(f"Average Epoch Time: {np.mean(self.training_history['epoch_time']):.2f}s")
        # Performance analysis
        perf_stats = self.cudnt.get_performance_stats()
        print(f"\nCUDNT Performance:")
        print(f"   GPU Operations: {perf_stats.get('device_switches', 0)}")
        print(f"   CPU Operations: {getattr(self.cudnt, '_cpu_ops', 0)}")
        print(f"   Memory Peak: {perf_stats.get('peak_memory_gb', 0):.2f} GB")

        # Learning analysis
        best_epoch = np.argmax(self.training_history['test_acc'])
        best_acc = self.training_history['test_acc'][best_epoch]

        print(f"\nBest Performance:")
        print(f"   Best Test Accuracy: {best_acc:.4f} (Epoch {best_epoch + 1})")
        print(f"   Final Train Accuracy: {self.training_history['train_acc'][-1]:.4f}")

        # Learning curve analysis
        if final_accuracy > 0.6:
            print("   ‚úÖ Excellent learning - structured data patterns recognized!")
        elif final_accuracy > 0.4:
            print("   ‚úÖ Good learning - model captured class distinctions")
        elif final_accuracy > 0.2:
            print("   ‚ö†Ô∏è Moderate learning - some patterns detected")
        else:
            print("   üîÑ Basic learning - random patterns still dominant")

    def save_demo_results(self):
        """Save demo results and create plots."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_dir = f"cudnt_cifar10_demo_{timestamp}"

        # Create results directory
        import os
        os.makedirs(results_dir, exist_ok=True)

        # Save training history
        with open(f"{results_dir}/training_history.json", 'w') as f:
            json.dump(self.training_history, f, indent=2)

        # Create learning curves plot
        self.create_learning_plot(results_dir)

        logger.info(f"üíæ Demo results saved to: {results_dir}")
        print(f"üìÅ Results saved to: {results_dir}/")

    def create_learning_plot(self, results_dir):
        """Create learning curves plot."""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))

        epochs = self.training_history['epoch']

        # Accuracy curves
        ax1.plot(epochs, self.training_history['train_acc'], 'b-', label='Train', linewidth=2, marker='o')
        ax1.plot(epochs, self.training_history['test_acc'], 'r-', label='Test', linewidth=2, marker='s')
        ax1.set_title('Model Accuracy - CUDNT Hybrid Training', fontsize=14, fontweight='bold')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Accuracy')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        ax1.set_ylim(0, 1)

        # Loss curves
        ax2.plot(epochs, self.training_history['train_loss'], 'b-', label='Train', linewidth=2, marker='o')
        ax2.plot(epochs, self.training_history['test_loss'], 'r-', label='Test', linewidth=2, marker='s')
        ax2.set_title('Model Loss - CUDNT Hybrid Training', fontsize=14, fontweight='bold')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Loss')
        ax2.legend()
        ax2.grid(True, alpha=0.3)

        # Learning rate schedule
        ax3.plot(epochs, self.training_history['learning_rate'], 'g-', linewidth=2, marker='^')
        ax3.set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')
        ax3.set_xlabel('Epoch')
        ax3.set_ylabel('Learning Rate')
        ax3.set_yscale('log')
        ax3.grid(True, alpha=0.3)

        # Epoch time
        ax4.plot(epochs, self.training_history['epoch_time'], 'm-', linewidth=2, marker='d')
        ax4.set_title('Training Time per Epoch', fontsize=14, fontweight='bold')
        ax4.set_xlabel('Epoch')
        ax4.set_ylabel('Time (seconds)')
        ax4.grid(True, alpha=0.3)

        plt.suptitle('CUDNT CIFAR-10 Training Demo - Hybrid GPU/CPU Acceleration',
                    fontsize=16, fontweight='bold', y=0.98)
        plt.tight_layout()
        plt.savefig(f"{results_dir}/cudnt_cifar10_learning_curves.png", dpi=300, bbox_inches='tight')
        plt.close()

        print(f"üìä Learning curves saved to: {results_dir}/cudnt_cifar10_learning_curves.png")

def run_cudnt_cifar10_demo():
    """Run the CUDNT CIFAR-10 training demo."""
    # Create demo trainer
    trainer = CUDNTCIFAR10Demo(
        batch_size=64,
        epochs=10,  # Quick demo
        learning_rate=0.01
    )

    # Run training
    results = trainer.run_training_demo()

    print("\nüéâ CUDNT CIFAR-10 Demo Complete!")
    print("=" * 35)
    print("‚úÖ Synthetic CIFAR-10 data with class patterns")
    print("‚úÖ Hybrid GPU/CPU training acceleration")
    print("‚úÖ Learning curves and validation metrics")
    print("‚úÖ Performance monitoring throughout training")
    print("‚úÖ Results saved with visualizations")

    return results

if __name__ == '__main__':
    # Run the demo
    demo_results = run_cudnt_cifar10_demo()
