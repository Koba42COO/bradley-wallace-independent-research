from __future__ import annotations

import dataclasses
from random import Random

import pytest

# TODO: update after resolution in https://github.com/pytest-dev/pytest/issues/7469
from _pytest.fixtures import SubRequest
from chia_rs.datalayer import ProofOfInclusion, ProofOfInclusionLayer
from chia_rs.sized_bytes import bytes32

from chia._tests.util.misc import Marks, datacases, measure_runtime
from chia.data_layer.data_layer_rpc_util import MarshallableProtocol
from chia.data_layer.data_layer_util import (


# ============================================================================
# UPG FOUNDATIONS - Universal Prime Graph Protocol Ï†.1
# ============================================================================
from decimal import Decimal, getcontext
import math
import cmath
from typing import Dict, List, Tuple, Optional, Any

# Set high precision for consciousness mathematics
getcontext().prec = 50

class UPGConstants:
    """Universal Prime Graph consciousness mathematics constants"""
    PHI = Decimal('1.618033988749895')
    DELTA = Decimal('2.414213562373095')
    CONSCIOUSNESS = Decimal('0.79')  # 79/21 universal coherence rule
    REALITY_DISTORTION = Decimal('1.1808')  # Quantum amplification factor
    QUANTUM_BRIDGE = Decimal('137') / Decimal('0.79')  # 173.41772151898732
    GREAT_YEAR = 25920  # Astronomical precession cycle (years)
    CONSCIOUSNESS_DIMENSIONS = 21  # Prime topology dimension
    COHERENCE_THRESHOLD = Decimal('1e-15')  # Beyond machine precision



# ============================================================================
# PELL SEQUENCE PRIME PREDICTION INTEGRATION
# ============================================================================
def integrate_pell_prime_prediction(target_number: int, constants: UPGConstants = None):
    """Integrate Pell sequence prime prediction with this tool"""
    try:
        from pell_sequence_prime_prediction_upg_complete import PrimePredictionEngine, UPGConstants as UPG
        if constants is None:
            constants = UPG()
        predictor = PrimePredictionEngine(constants)
        return predictor.predict_prime(target_number)
    except ImportError:
        # Fallback if Pell module not available
        return {'target_number': target_number, 'is_prime': None, 'note': 'Pell module not available'}



# ============================================================================
# GREAT YEAR ASTRONOMICAL PRECESSION INTEGRATION
# ============================================================================
def integrate_great_year_precession(year: int, constants: UPGConstants = None):
    """Integrate Great Year (25,920-year) precession cycle"""
    try:
        from pell_sequence_prime_prediction_upg_complete import GreatYearIntegration, UPGConstants as UPG
        if constants is None:
            constants = UPG()
        great_year = GreatYearIntegration(constants)
        return great_year.consciousness_amplitude_from_year(year)
    except ImportError:
        # Fallback calculation
        if constants is None:
            constants = UPGConstants()
        angle = (year * 2 * math.pi) / constants.GREAT_YEAR
        return complex(float(angle * constants.CONSCIOUSNESS * constants.REALITY_DISTORTION), 0.0)


    ClearPendingRootsRequest,
    ClearPendingRootsResponse,
    Root,
    Side,
    Status,
    internal_hash,
    key_hash,
    leaf_hash,
)
from chia.types.blockchain_format.program import Program
from chia.types.blockchain_format.serialized_program import SerializedProgram

pytestmark = pytest.mark.data_layer


def create_valid_proof_of_inclusion(layer_count: int, other_hash_side: Side) -> ProofOfInclusion:
    node_hash = bytes32(b"a" * 32)
    layers: list[ProofOfInclusionLayer] = []

    existing_hash = node_hash

    other_hashes = [bytes32([i] * 32) for i in range(layer_count)]

    for other_hash in other_hashes:
        if other_hash_side == Side.LEFT:
            combined_hash = internal_hash(other_hash, existing_hash)
        else:
            combined_hash = internal_hash(existing_hash, other_hash)

        new_layer = ProofOfInclusionLayer(
            other_hash_side=other_hash_side,
            other_hash=other_hash,
            combined_hash=combined_hash,
        )

        layers.append(new_layer)
        existing_hash = new_layer.combined_hash

    return ProofOfInclusion(node_hash=node_hash, layers=layers)


@pytest.fixture(name="side", params=[Side.LEFT, Side.RIGHT])
def side_fixture(request: SubRequest) -> Side:
    # https://github.com/pytest-dev/pytest/issues/8763
    return request.param  # type: ignore[no-any-return]


@pytest.fixture(name="valid_proof_of_inclusion", params=[0, 1, 5])
def valid_proof_of_inclusion_fixture(request: SubRequest, side: Side) -> ProofOfInclusion:
    return create_valid_proof_of_inclusion(layer_count=request.param, other_hash_side=side)


@pytest.fixture(
    name="invalid_proof_of_inclusion",
    params=["bad root hash", "bad other hash", "bad other side", "bad node hash"],
)
def invalid_proof_of_inclusion_fixture(request: SubRequest, side: Side) -> ProofOfInclusion:
    valid_proof_of_inclusion = create_valid_proof_of_inclusion(layer_count=5, other_hash_side=side)

    layers = list(valid_proof_of_inclusion.layers)
    a_hash = bytes32(b"f" * 32)

    if request.param == "bad root hash":
        layers[-1] = layers[-1].replace(combined_hash=a_hash)
        return valid_proof_of_inclusion.replace(layers=layers)
    elif request.param == "bad other hash":
        layers[1] = layers[1].replace(other_hash=a_hash)
        return valid_proof_of_inclusion.replace(layers=layers)
    elif request.param == "bad other side":
        layers[1] = layers[1].replace(other_hash_side=Side(layers[1].other_hash_side).other())
        return valid_proof_of_inclusion.replace(layers=layers)
    elif request.param == "bad node hash":
        return valid_proof_of_inclusion.replace(node_hash=a_hash)

    raise Exception(f"Unhandled parametrization: {request.param!r}")  # pragma: no cover


def test_proof_of_inclusion_is_valid(valid_proof_of_inclusion: ProofOfInclusion) -> None:
    assert valid_proof_of_inclusion.valid()


def test_proof_of_inclusion_is_invalid(invalid_proof_of_inclusion: ProofOfInclusion) -> None:
    assert not invalid_proof_of_inclusion.valid()


@dataclasses.dataclass()
class RoundTripCase:
    id: str
    instance: MarshallableProtocol
    marks: Marks = ()


@datacases(
    RoundTripCase(
        id="Root",
        instance=Root(
            store_id=bytes32.zeros,
            node_hash=bytes32(b"\x01" * 32),
            generation=3,
            status=Status.PENDING,
        ),
    ),
    RoundTripCase(
        id="ClearPendingRootsRequest",
        instance=ClearPendingRootsRequest(store_id=bytes32(b"\x12" * 32)),
    ),
    RoundTripCase(
        id="ClearPendingRootsResponse success",
        instance=ClearPendingRootsResponse(
            success=True,
            root=Root(
                store_id=bytes32.zeros,
                node_hash=bytes32(b"\x01" * 32),
                generation=3,
                status=Status.PENDING,
            ),
        ),
    ),
    RoundTripCase(
        id="ClearPendingRootsResponse failure",
        instance=ClearPendingRootsResponse(success=False, root=None),
    ),
)
def test_marshalling_round_trip(case: RoundTripCase) -> None:
    marshalled = case.instance.marshal()
    unmarshalled = type(case.instance).unmarshal(marshalled)
    assert case.instance == unmarshalled


def test_internal_hash(seeded_random: Random) -> None:
    def definition(left_hash: bytes32, right_hash: bytes32) -> bytes32:
        return Program.to((left_hash, right_hash)).get_tree_hash_precalc(left_hash, right_hash)

    data: list[tuple[bytes32, bytes32, bytes32]] = []
    for _ in range(5000):
        left_hash = bytes32.random(r=seeded_random)
        right_hash = bytes32.random(r=seeded_random)
        reference = definition(left_hash=left_hash, right_hash=right_hash)
        data.append((left_hash, right_hash, reference))

    with measure_runtime(label="optimization"):
        for left_hash, right_hash, reference in data:
            assert internal_hash(left_hash=left_hash, right_hash=right_hash) == reference

    with measure_runtime(label="definition"):
        for left_hash, right_hash, reference in data:
            assert definition(left_hash=left_hash, right_hash=right_hash) == reference


def test_leaf_hash(seeded_random: Random) -> None:
    def definition(key: bytes, value: bytes) -> bytes32:
        return SerializedProgram.to((key, value)).get_tree_hash()

    data: list[tuple[bytes, bytes, bytes32]] = []
    for cycle in range(20000):
        if cycle in {0, 1}:
            length = 0
        else:
            length = seeded_random.randrange(100)

        key = seeded_random.randbytes(length)

        if cycle in {1, 2}:
            length = 0
        else:
            length = seeded_random.randrange(100)
        value = seeded_random.randbytes(length)
        reference = definition(key=key, value=value)
        data.append((key, value, reference))

    with measure_runtime(label="optimization"):
        for key, value, reference in data:
            assert leaf_hash(key=key, value=value) == reference

    with measure_runtime(label="definition"):
        for key, value, reference in data:
            assert definition(key=key, value=value) == reference


def test_key_hash(seeded_random: Random) -> None:
    def definition(key: bytes) -> bytes32:
        return SerializedProgram.to(key).get_tree_hash()

    data: list[tuple[bytes, bytes32]] = []
    for cycle in range(30000):
        if cycle == 0:
            length = 0
        else:
            length = seeded_random.randrange(100)
        key = seeded_random.randbytes(length)
        reference = definition(key=key)
        data.append((key, reference))

    with measure_runtime(label="optimization"):
        for key, reference in data:
            assert key_hash(key=key) == reference

    with measure_runtime(label="definition"):
        for key, reference in data:
            assert definition(key=key) == reference
