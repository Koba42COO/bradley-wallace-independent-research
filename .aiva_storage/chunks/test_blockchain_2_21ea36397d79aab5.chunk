            await b.add_block(
                blocks[-1],
                PreValidationResult(None, uint64(1), npc_result.conds.replace(validated_signature=True), uint32(0)),
                sub_slot_iters=ssi,
                fork_info=fork_info,
            )
        )[1]
        assert err == Err.BLOCK_COST_EXCEEDS_MAX
        future = await pre_validate_block(
            b.constants,
            AugmentedBlockchain(b),
            blocks[-1],
            b.pool,
            None,
            ValidationState(ssi, diff, None),
        )
        result: PreValidationResult = await future
        assert Err(result.error) == Err.BLOCK_COST_EXCEEDS_MAX

    @pytest.mark.anyio
    async def test_clvm_must_not_fail(self, empty_blockchain: Blockchain, bt: BlockTools) -> None:
        # 8
        pass

    @pytest.mark.anyio
    async def test_invalid_cost_in_block(
        self, empty_blockchain: Blockchain, softfork_height: uint32, bt: BlockTools
    ) -> None:
        # 9
        b = empty_blockchain
        blocks = bt.get_consecutive_blocks(
            3,
            guarantee_transaction_block=True,
            farmer_reward_puzzle_hash=bt.pool_ph,
            pool_reward_puzzle_hash=bt.pool_ph,
        )
        await _validate_and_add_block(b, blocks[0])
        await _validate_and_add_block(b, blocks[1])
        await _validate_and_add_block(b, blocks[2])

        wt: WalletTool = bt.get_pool_wallet_tool()

        tx = wt.generate_signed_transaction(
            uint64(10), wt.get_new_puzzlehash(), blocks[-1].get_included_reward_coins()[0]
        )

        blocks = bt.get_consecutive_blocks(
            1, block_list_input=blocks, guarantee_transaction_block=True, transaction_data=tx
        )
        block: FullBlock = blocks[-1]

        # zero
        block_2: FullBlock = recursive_replace(block, "transactions_info.cost", uint64(0))
        assert block_2.transactions_info is not None
        block_2 = recursive_replace(
            block_2, "foliage_transaction_block.transactions_info_hash", block_2.transactions_info.get_hash()
        )
        assert block_2.foliage_transaction_block is not None
        block_2 = recursive_replace(
            block_2, "foliage.foliage_transaction_block_hash", block_2.foliage_transaction_block.get_hash()
        )
        new_m = block_2.foliage.foliage_transaction_block_hash
        assert new_m is not None
        new_fsb_sig = bt.get_plot_signature(new_m, block.reward_chain_block.proof_of_space.plot_public_key)
        block_2 = recursive_replace(block_2, "foliage.foliage_transaction_block_signature", new_fsb_sig)
        assert block_2.transactions_generator is not None
        block_generator = BlockGenerator(block_2.transactions_generator, [])
        assert block.transactions_info is not None
        npc_result = get_name_puzzle_conditions(
            block_generator,
            min(b.constants.MAX_BLOCK_COST_CLVM * 1000, block.transactions_info.cost),
            mempool_mode=False,
            height=softfork_height,
            constants=bt.constants,
        )
        assert npc_result.conds is not None
        ssi = b.constants.SUB_SLOT_ITERS_STARTING
        fork_info = ForkInfo(block_2.height - 1, block_2.height - 1, block_2.prev_header_hash)
        _, err, _ = await b.add_block(
            block_2,
            PreValidationResult(None, uint64(1), npc_result.conds.replace(validated_signature=True), uint32(0)),
            sub_slot_iters=ssi,
            fork_info=fork_info,
        )
        assert err == Err.INVALID_BLOCK_COST

        # too low
        block_2 = recursive_replace(block, "transactions_info.cost", uint64(1))
        assert block_2.transactions_info is not None
        block_2 = recursive_replace(
            block_2, "foliage_transaction_block.transactions_info_hash", block_2.transactions_info.get_hash()
        )
        assert block_2.foliage_transaction_block is not None
        block_2 = recursive_replace(
            block_2, "foliage.foliage_transaction_block_hash", block_2.foliage_transaction_block.get_hash()
        )
        new_m = block_2.foliage.foliage_transaction_block_hash
        assert new_m is not None
        new_fsb_sig = bt.get_plot_signature(new_m, block.reward_chain_block.proof_of_space.plot_public_key)
        block_2 = recursive_replace(block_2, "foliage.foliage_transaction_block_signature", new_fsb_sig)
        assert block_2.transactions_generator is not None
        block_generator = BlockGenerator(block_2.transactions_generator, [])
        assert block.transactions_info is not None
        npc_result = get_name_puzzle_conditions(
            block_generator,
            min(b.constants.MAX_BLOCK_COST_CLVM * 1000, block.transactions_info.cost),
            mempool_mode=False,
            height=softfork_height,
            constants=bt.constants,
        )
        assert npc_result.conds is not None
        fork_info = ForkInfo(block_2.height - 1, block_2.height - 1, block_2.prev_header_hash)
        _, err, _ = await b.add_block(
            block_2,
            PreValidationResult(None, uint64(1), npc_result.conds.replace(validated_signature=True), uint32(0)),
            sub_slot_iters=ssi,
            fork_info=fork_info,
        )
        assert err == Err.INVALID_BLOCK_COST

        # too high
        block_2 = recursive_replace(block, "transactions_info.cost", uint64(1000000))
        assert block_2.transactions_info is not None
        block_2 = recursive_replace(
            block_2, "foliage_transaction_block.transactions_info_hash", block_2.transactions_info.get_hash()
        )
        assert block_2.foliage_transaction_block is not None
        block_2 = recursive_replace(
            block_2, "foliage.foliage_transaction_block_hash", block_2.foliage_transaction_block.get_hash()
        )
        new_m = block_2.foliage.foliage_transaction_block_hash
        assert new_m is not None
        new_fsb_sig = bt.get_plot_signature(new_m, block.reward_chain_block.proof_of_space.plot_public_key)
        block_2 = recursive_replace(block_2, "foliage.foliage_transaction_block_signature", new_fsb_sig)

        assert block_2.transactions_generator is not None
        block_generator = BlockGenerator(block_2.transactions_generator, [])
        max_cost = (
            min(b.constants.MAX_BLOCK_COST_CLVM * 1000, block.transactions_info.cost)
            if block.transactions_info is not None
            else b.constants.MAX_BLOCK_COST_CLVM * 1000
        )
        npc_result = get_name_puzzle_conditions(
            block_generator,
            max_cost,
            mempool_mode=False,
            height=softfork_height,
            constants=bt.constants,
        )
        assert npc_result.conds is not None
        fork_info = ForkInfo(block_2.height - 1, block_2.height - 1, block_2.prev_header_hash)
        _result, err, _ = await b.add_block(
            block_2,
            PreValidationResult(None, uint64(1), npc_result.conds.replace(validated_signature=True), uint32(0)),
            sub_slot_iters=ssi,
            fork_info=fork_info,
        )
        assert err == Err.INVALID_BLOCK_COST

        # when the CLVM program exceeds cost during execution, it will fail with
        # a general runtime error. The previous test tests this.

    @pytest.mark.anyio
    async def test_max_coin_amount(self, db_version: int, bt: BlockTools) -> None:
        # 10
        # TODO: fix, this is not reaching validation. Because we can't create a block with such amounts due to uint64
        # limit in Coin
        pass
        #
        # with TempKeyring() as keychain:
        #     new_test_constants = bt.constants.replace(
        #         GENESIS_PRE_FARM_POOL_PUZZLE_HASH=bt.pool_ph,
        #         GENESIS_PRE_FARM_FARMER_PUZZLE_HASH=bt.pool_ph,
        #     )
        #     b, db_wrapper = await create_blockchain(new_test_constants, db_version)
        #     bt_2 = await create_block_tools_async(constants=new_test_constants, keychain=keychain)
        #     bt_2.constants = bt_2.constants.replace(
        #         GENESIS_PRE_FARM_POOL_PUZZLE_HASH=bt.pool_ph,
        #         GENESIS_PRE_FARM_FARMER_PUZZLE_HASH=bt.pool_ph,
        #     )
        #     blocks = bt_2.get_consecutive_blocks(
        #         3,
        #         guarantee_transaction_block=True,
        #         farmer_reward_puzzle_hash=bt.pool_ph,
        #         pool_reward_puzzle_hash=bt.pool_ph,
        #     )
        #     assert (await b.add_block(blocks[0]))[0] == AddBlockResult.NEW_PEAK
        #     assert (await b.add_block(blocks[1]))[0] == AddBlockResult.NEW_PEAK
        #     assert (await b.add_block(blocks[2]))[0] == AddBlockResult.NEW_PEAK

        #     wt: WalletTool = bt_2.get_pool_wallet_tool()

        #     condition_dict: dict[ConditionOpcode, list[ConditionWithArgs]] = {ConditionOpcode.CREATE_COIN: []}
        #     output = ConditionWithArgs(ConditionOpcode.CREATE_COIN, [bt_2.pool_ph, int_to_bytes(2 ** 64)])
        #     condition_dict[ConditionOpcode.CREATE_COIN].append(output)

        #     tx = wt.generate_signed_transaction_multiple_coins(
        #         uint64(10),
        #         wt.get_new_puzzlehash(),
        #         blocks[1].get_included_reward_coins(),
        #         condition_dic=condition_dict,
        #     )
        #     with pytest.raises(Exception):
        #         blocks = bt_2.get_consecutive_blocks(
        #             1, block_list_input=blocks, guarantee_transaction_block=True, transaction_data=tx
        #         )
        #     await db_wrapper.close()
        #     b.shut_down()

    @pytest.mark.anyio
    async def test_invalid_merkle_roots(self, empty_blockchain: Blockchain, bt: BlockTools) -> None:
        # 11
        blocks = bt.get_consecutive_blocks(
            3,
            guarantee_transaction_block=True,
            farmer_reward_puzzle_hash=bt.pool_ph,
            pool_reward_puzzle_hash=bt.pool_ph,
        )
        await _validate_and_add_block(empty_blockchain, blocks[0])
        await _validate_and_add_block(empty_blockchain, blocks[1])
        await _validate_and_add_block(empty_blockchain, blocks[2])

        wt: WalletTool = bt.get_pool_wallet_tool()

        tx = wt.generate_signed_transaction(
            uint64(10), wt.get_new_puzzlehash(), blocks[-1].get_included_reward_coins()[0]
        )

        blocks = bt.get_consecutive_blocks(
            1, block_list_input=blocks, guarantee_transaction_block=True, transaction_data=tx
        )
        block: FullBlock = blocks[-1]

        merkle_set = MerkleSet([])
        # additions
        block_2 = recursive_replace(block, "foliage_transaction_block.additions_root", merkle_set.get_root())
        block_2 = recursive_replace(
            block_2, "foliage.foliage_transaction_block_hash", block_2.foliage_transaction_block.get_hash()
        )
        new_m = block_2.foliage.foliage_transaction_block_hash
        assert new_m is not None
        new_fsb_sig = bt.get_plot_signature(new_m, block.reward_chain_block.proof_of_space.plot_public_key)
        block_2 = recursive_replace(block_2, "foliage.foliage_transaction_block_signature", new_fsb_sig)

        await _validate_and_add_block(empty_blockchain, block_2, expected_error=Err.BAD_ADDITION_ROOT)

        # removals
        merkle_set = MerkleSet([std_hash(b"1")])
        block_2 = recursive_replace(block, "foliage_transaction_block.removals_root", merkle_set.get_root())
        block_2 = recursive_replace(
            block_2, "foliage.foliage_transaction_block_hash", block_2.foliage_transaction_block.get_hash()
        )
        new_m = block_2.foliage.foliage_transaction_block_hash
        assert new_m is not None
        new_fsb_sig = bt.get_plot_signature(new_m, block.reward_chain_block.proof_of_space.plot_public_key)
        block_2 = recursive_replace(block_2, "foliage.foliage_transaction_block_signature", new_fsb_sig)

        await _validate_and_add_block(empty_blockchain, block_2, expected_error=Err.BAD_REMOVAL_ROOT)

    @pytest.mark.anyio
    async def test_invalid_filter(self, empty_blockchain: Blockchain, bt: BlockTools) -> None:
        # 12
        b = empty_blockchain
        blocks = bt.get_consecutive_blocks(
            3,
            guarantee_transaction_block=True,
            farmer_reward_puzzle_hash=bt.pool_ph,
            pool_reward_puzzle_hash=bt.pool_ph,
        )
        await _validate_and_add_block(b, blocks[0])
        await _validate_and_add_block(b, blocks[1])
        await _validate_and_add_block(b, blocks[2])

        wt: WalletTool = bt.get_pool_wallet_tool()

        tx = wt.generate_signed_transaction(
            uint64(10), wt.get_new_puzzlehash(), blocks[-1].get_included_reward_coins()[0]
        )

        blocks = bt.get_consecutive_blocks(
            1, block_list_input=blocks, guarantee_transaction_block=True, transaction_data=tx
        )
        block: FullBlock = blocks[-1]
        block_2 = recursive_replace(block, "foliage_transaction_block.filter_hash", std_hash(b"3"))
        block_2 = recursive_replace(
            block_2, "foliage.foliage_transaction_block_hash", block_2.foliage_transaction_block.get_hash()
        )
        new_m = block_2.foliage.foliage_transaction_block_hash
        assert new_m is not None
        new_fsb_sig = bt.get_plot_signature(new_m, block.reward_chain_block.proof_of_space.plot_public_key)
        block_2 = recursive_replace(block_2, "foliage.foliage_transaction_block_signature", new_fsb_sig)

        await _validate_and_add_block(b, block_2, expected_error=Err.INVALID_TRANSACTIONS_FILTER_HASH)

    @pytest.mark.anyio
    async def test_duplicate_outputs(self, empty_blockchain: Blockchain, bt: BlockTools) -> None:
        # 13
        b = empty_blockchain
        blocks = bt.get_consecutive_blocks(
            3,
            guarantee_transaction_block=True,
            farmer_reward_puzzle_hash=bt.pool_ph,
            pool_reward_puzzle_hash=bt.pool_ph,
        )
        await _validate_and_add_block(b, blocks[0])
        await _validate_and_add_block(b, blocks[1])
        await _validate_and_add_block(b, blocks[2])

        wt: WalletTool = bt.get_pool_wallet_tool()

        condition_dict: dict[ConditionOpcode, list[ConditionWithArgs]] = {ConditionOpcode.CREATE_COIN: []}
        for _ in range(2):
            output = ConditionWithArgs(ConditionOpcode.CREATE_COIN, [bt.pool_ph, int_to_bytes(1)])
            condition_dict[ConditionOpcode.CREATE_COIN].append(output)

        tx = wt.generate_signed_transaction(
            uint64(10), wt.get_new_puzzlehash(), blocks[-1].get_included_reward_coins()[0], condition_dic=condition_dict
        )

        blocks = bt.get_consecutive_blocks(
            1, block_list_input=blocks, guarantee_transaction_block=True, transaction_data=tx
        )
        await _validate_and_add_block(b, blocks[-1], expected_error=Err.DUPLICATE_OUTPUT)

    @pytest.mark.anyio
    async def test_duplicate_removals(self, empty_blockchain: Blockchain, bt: BlockTools) -> None:
        # 14
        b = empty_blockchain
        blocks = bt.get_consecutive_blocks(
            3,
            guarantee_transaction_block=True,
            farmer_reward_puzzle_hash=bt.pool_ph,
            pool_reward_puzzle_hash=bt.pool_ph,
        )
        await _validate_and_add_block(b, blocks[0])
        await _validate_and_add_block(b, blocks[1])
        await _validate_and_add_block(b, blocks[2])

        wt: WalletTool = bt.get_pool_wallet_tool()

        tx = wt.generate_signed_transaction(
            uint64(10), wt.get_new_puzzlehash(), blocks[-1].get_included_reward_coins()[0]
        )
        tx_2 = wt.generate_signed_transaction(
            uint64(11), wt.get_new_puzzlehash(), blocks[-1].get_included_reward_coins()[0]
        )
        agg = SpendBundle.aggregate([tx, tx_2])

        blocks = bt.get_consecutive_blocks(
            1, block_list_input=blocks, guarantee_transaction_block=True, transaction_data=agg
        )
        await _validate_and_add_block(b, blocks[-1], expected_error=Err.DOUBLE_SPEND)

    @pytest.mark.anyio
    async def test_double_spent_in_coin_store(self, empty_blockchain: Blockchain, bt: BlockTools) -> None:
        # 15
        b = empty_blockchain
        blocks = bt.get_consecutive_blocks(
            3,
            guarantee_transaction_block=True,
            farmer_reward_puzzle_hash=bt.pool_ph,
            pool_reward_puzzle_hash=bt.pool_ph,
        )
        await _validate_and_add_block(b, blocks[0])
        await _validate_and_add_block(b, blocks[1])
        await _validate_and_add_block(b, blocks[2])

        wt: WalletTool = bt.get_pool_wallet_tool()

        tx = wt.generate_signed_transaction(
            uint64(10), wt.get_new_puzzlehash(), blocks[-1].get_included_reward_coins()[0]
        )

        blocks = bt.get_consecutive_blocks(
            1, block_list_input=blocks, guarantee_transaction_block=True, transaction_data=tx
        )
        await _validate_and_add_block(b, blocks[-1])

        tx_2 = wt.generate_signed_transaction(
            uint64(10), wt.get_new_puzzlehash(), blocks[-2].get_included_reward_coins()[0]
        )
        blocks = bt.get_consecutive_blocks(
            1, block_list_input=blocks, guarantee_transaction_block=True, transaction_data=tx_2
        )

        await _validate_and_add_block(b, blocks[-1], expected_error=Err.DOUBLE_SPEND)

    @pytest.mark.anyio
    async def test_double_spent_in_reorg(self, empty_blockchain: Blockchain, bt: BlockTools) -> None:
        # 15
        b = empty_blockchain
        blocks = bt.get_consecutive_blocks(
            3,
            guarantee_transaction_block=True,
            farmer_reward_puzzle_hash=bt.pool_ph,
            pool_reward_puzzle_hash=bt.pool_ph,
        )
        await _validate_and_add_block(b, blocks[0])
        await _validate_and_add_block(b, blocks[1])
        await _validate_and_add_block(b, blocks[2])

        wt: WalletTool = bt.get_pool_wallet_tool()

        tx = wt.generate_signed_transaction(
            uint64(10), wt.get_new_puzzlehash(), blocks[-1].get_included_reward_coins()[0]
        )
        blocks = bt.get_consecutive_blocks(
            1, block_list_input=blocks, guarantee_transaction_block=True, transaction_data=tx
        )
        await _validate_and_add_block(b, blocks[-1])

        new_coin: Coin = tx.additions()[0]
        tx_2 = wt.generate_signed_transaction(uint64(10), wt.get_new_puzzlehash(), new_coin)
        # This is fine because coin exists
        blocks = bt.get_consecutive_blocks(
            1, block_list_input=blocks, guarantee_transaction_block=True, transaction_data=tx_2
        )
        await _validate_and_add_block(b, blocks[-1])
        blocks = bt.get_consecutive_blocks(5, block_list_input=blocks, guarantee_transaction_block=True)
        for block in blocks[-5:]:
            await _validate_and_add_block(b, block)

        blocks_reorg = bt.get_consecutive_blocks(2, block_list_input=blocks[:-7], guarantee_transaction_block=True)
        fork_info = ForkInfo(blocks[-8].height, blocks[-8].height, blocks[-8].header_hash)
        await _validate_and_add_block(
            b, blocks_reorg[-2], expected_result=AddBlockResult.ADDED_AS_ORPHAN, fork_info=fork_info
        )
        await _validate_and_add_block(
            b, blocks_reorg[-1], expected_result=AddBlockResult.ADDED_AS_ORPHAN, fork_info=fork_info
        )

        # Coin does not exist in reorg
        blocks_reorg = bt.get_consecutive_blocks(
            1, block_list_input=blocks_reorg, guarantee_transaction_block=True, transaction_data=tx_2
        )
        peak = b.get_peak()
        assert peak is not None
        await _validate_and_add_block(b, blocks_reorg[-1], expected_error=Err.UNKNOWN_UNSPENT, fork_info=fork_info)

        # Finally add the block to the fork (spending both in same bundle, this is ephemeral)
        agg = SpendBundle.aggregate([tx, tx_2])
        blocks_reorg = bt.get_consecutive_blocks(
            1, block_list_input=blocks_reorg[:-1], guarantee_transaction_block=True, transaction_data=agg
        )

        peak = b.get_peak()
        assert peak is not None
        await _validate_and_add_block(
            b, blocks_reorg[-1], expected_result=AddBlockResult.ADDED_AS_ORPHAN, fork_info=fork_info
        )

        blocks_reorg = bt.get_consecutive_blocks(
            1, block_list_input=blocks_reorg, guarantee_transaction_block=True, transaction_data=tx_2
        )
        peak = b.get_peak()
        assert peak is not None
        await _validate_and_add_block(b, blocks_reorg[-1], expected_error=Err.DOUBLE_SPEND_IN_FORK, fork_info=fork_info)

        rewards_ph = wt.get_new_puzzlehash()
        blocks_reorg = bt.get_consecutive_blocks(
            10,
            block_list_input=blocks_reorg[:-1],
            guarantee_transaction_block=True,
            farmer_reward_puzzle_hash=rewards_ph,
        )

        peak = b.get_peak()
        assert peak is not None
        for block in blocks_reorg[-10:]:
            await _validate_and_add_block_multi_result(
                b, block, expected_result=[AddBlockResult.ADDED_AS_ORPHAN, AddBlockResult.NEW_PEAK], fork_info=fork_info
            )

        # ephemeral coin is spent
        first_coin = await b.coin_store.get_coin_record(new_coin.name())
        assert first_coin is not None and first_coin.spent
        second_coin = await b.coin_store.get_coin_record(tx_2.additions()[0].name())
        assert second_coin is not None and not second_coin.spent

        farmer_coin = create_farmer_coin(
            blocks_reorg[-1].height,
            rewards_ph,
            calculate_base_farmer_reward(blocks_reorg[-1].height),
            bt.constants.GENESIS_CHALLENGE,
        )
        tx_3 = wt.generate_signed_transaction(uint64(10), wt.get_new_puzzlehash(), farmer_coin)

        blocks_reorg = bt.get_consecutive_blocks(
            1, block_list_input=blocks_reorg, guarantee_transaction_block=True, transaction_data=tx_3
        )
        await _validate_and_add_block(b, blocks_reorg[-1])

        farmer_coin_record = await b.coin_store.get_coin_record(farmer_coin.name())
        assert farmer_coin_record is not None and farmer_coin_record.spent

    @pytest.mark.anyio
    async def test_minting_coin(self, empty_blockchain: Blockchain, bt: BlockTools) -> None:
        # 16 Minting coin check
        b = empty_blockchain
        blocks = bt.get_consecutive_blocks(
            3,
            guarantee_transaction_block=True,
            farmer_reward_puzzle_hash=bt.pool_ph,
            pool_reward_puzzle_hash=bt.pool_ph,
        )
        await _validate_and_add_block(b, blocks[0])
        await _validate_and_add_block(b, blocks[1])
        await _validate_and_add_block(b, blocks[2])

        wt: WalletTool = bt.get_pool_wallet_tool()

        spend = blocks[-1].get_included_reward_coins()[0]
        print("spend=", spend)
        # this create coin will spend all of the coin, so the 10 mojos below
        # will be "minted".
        output = ConditionWithArgs(ConditionOpcode.CREATE_COIN, [bt.pool_ph, int_to_bytes(spend.amount)])
        condition_dict = {ConditionOpcode.CREATE_COIN: [output]}

        tx = wt.generate_signed_transaction(uint64(10), wt.get_new_puzzlehash(), spend, condition_dic=condition_dict)

        blocks = bt.get_consecutive_blocks(
            1, block_list_input=blocks, guarantee_transaction_block=True, transaction_data=tx
        )
        await _validate_and_add_block(b, blocks[-1], expected_error=Err.MINTING_COIN)
        # 17 is tested in mempool tests

    @pytest.mark.anyio
    async def test_max_coin_amount_fee(self) -> None:
        # 18 TODO: we can't create a block with such amounts due to uint64
        pass

    @pytest.mark.anyio
    async def test_invalid_fees_in_block(self, empty_blockchain: Blockchain, bt: BlockTools) -> None:
        # 19
        b = empty_blockchain
        blocks = bt.get_consecutive_blocks(
            3,
            guarantee_transaction_block=True,
            farmer_reward_puzzle_hash=bt.pool_ph,
            pool_reward_puzzle_hash=bt.pool_ph,
        )
        await _validate_and_add_block(b, blocks[0])
        await _validate_and_add_block(b, blocks[1])
        await _validate_and_add_block(b, blocks[2])

        wt: WalletTool = bt.get_pool_wallet_tool()

        tx = wt.generate_signed_transaction(
            uint64(10), wt.get_new_puzzlehash(), blocks[-1].get_included_reward_coins()[0]
        )

        blocks = bt.get_consecutive_blocks(
            1, block_list_input=blocks, guarantee_transaction_block=True, transaction_data=tx
        )
        block: FullBlock = blocks[-1]

        # wrong feees
        block_2: FullBlock = recursive_replace(block, "transactions_info.fees", uint64(1239))
        assert block_2.transactions_info is not None
        block_2 = recursive_replace(
            block_2, "foliage_transaction_block.transactions_info_hash", block_2.transactions_info.get_hash()
        )
        assert block_2.foliage_transaction_block is not None
        block_2 = recursive_replace(
            block_2, "foliage.foliage_transaction_block_hash", block_2.foliage_transaction_block.get_hash()
        )
        new_m = block_2.foliage.foliage_transaction_block_hash
        assert new_m is not None
        new_fsb_sig = bt.get_plot_signature(new_m, block.reward_chain_block.proof_of_space.plot_public_key)
        block_2 = recursive_replace(block_2, "foliage.foliage_transaction_block_signature", new_fsb_sig)

        await _validate_and_add_block(b, block_2, expected_error=Err.INVALID_BLOCK_FEE_AMOUNT)

    @pytest.mark.anyio
    async def test_invalid_agg_sig(self, empty_blockchain: Blockchain, bt: BlockTools) -> None:
        # 22
        b = empty_blockchain
        blocks = bt.get_consecutive_blocks(
            3,
            guarantee_transaction_block=True,
            farmer_reward_puzzle_hash=bt.pool_ph,
            pool_reward_puzzle_hash=bt.pool_ph,
        )
        await _validate_and_add_block(b, blocks[0])
        await _validate_and_add_block(b, blocks[1])
        await _validate_and_add_block(b, blocks[2])

        wt: WalletTool = bt.get_pool_wallet_tool()

        tx = wt.generate_signed_transaction(
            uint64(10), wt.get_new_puzzlehash(), blocks[-1].get_included_reward_coins()[0]
        )
        blocks = bt.get_consecutive_blocks(
            1, block_list_input=blocks, guarantee_transaction_block=True, transaction_data=tx
        )

        last_block = recursive_replace(blocks[-1], "transactions_info.aggregated_signature", G2Element.generator())
        assert last_block.transactions_info is not None
        last_block = recursive_replace(
            last_block, "foliage_transaction_block.transactions_info_hash", last_block.transactions_info.get_hash()
        )
        assert last_block.foliage_transaction_block is not None
        last_block = recursive_replace(
            last_block, "foliage.foliage_transaction_block_hash", last_block.foliage_transaction_block.get_hash()
        )
        new_m = last_block.foliage.foliage_transaction_block_hash
        assert new_m is not None
        new_fsb_sig = bt.get_plot_signature(new_m, last_block.reward_chain_block.proof_of_space.plot_public_key)
        last_block = recursive_replace(last_block, "foliage.foliage_transaction_block_signature", new_fsb_sig)

        # Bad signature fails during add_block
        await _validate_and_add_block(b, last_block, expected_error=Err.BAD_AGGREGATE_SIGNATURE)

        # Bad signature also fails in prevalidation
        ssi = b.constants.SUB_SLOT_ITERS_STARTING
        diff = b.constants.DIFFICULTY_STARTING
        future = await pre_validate_block(
            b.constants,
            AugmentedBlockchain(b),
            last_block,
            b.pool,
            None,
            ValidationState(ssi, diff, None),
        )
        preval_result: PreValidationResult = await future
        assert preval_result.error == Err.BAD_AGGREGATE_SIGNATURE.value


def maybe_header_hash(block: Optional[BlockRecord]) -> Optional[bytes32]:
    if block is None:
        return None
    return block.header_hash


class TestReorgs:
    @pytest.mark.anyio
    async def test_basic_reorg(self, empty_blockchain: Blockchain, bt: BlockTools) -> None:
        b = empty_blockchain
        blocks = bt.get_consecutive_blocks(15)

        for block in blocks:
            await _validate_and_add_block(b, block)
        peak = b.get_peak()
        assert peak is not None
        assert peak.height == 14

        blocks_reorg_chain = bt.get_consecutive_blocks(7, blocks[:10], seed=b"2")
        fork_info = ForkInfo(-1, -1, bt.constants.GENESIS_CHALLENGE)
        for reorg_block in blocks_reorg_chain:
            if reorg_block.height < 10:
                await _validate_and_add_block(
                    b, reorg_block, expected_result=AddBlockResult.ALREADY_HAVE_BLOCK, fork_info=fork_info
                )
            elif reorg_block.height < 15:
                await _validate_and_add_block(
                    b, reorg_block, expected_result=AddBlockResult.ADDED_AS_ORPHAN, fork_info=fork_info
                )
            elif reorg_block.height >= 15:
                await _validate_and_add_block(b, reorg_block, fork_info=fork_info)
        peak = b.get_peak()
        assert peak is not None
        assert peak.height == 16

    @pytest.mark.anyio
    async def test_get_tx_peak_reorg(
        self, empty_blockchain: Blockchain, bt: BlockTools, consensus_mode: ConsensusMode
    ) -> None:
        b = empty_blockchain

        if consensus_mode < ConsensusMode.HARD_FORK_2_0:
            reorg_point = 13
        else:
            reorg_point = 12
        blocks = bt.get_consecutive_blocks(reorg_point)

        last_tx_block: Optional[bytes32] = None
        for block in blocks:
            assert maybe_header_hash(b.get_tx_peak()) == last_tx_block
            await _validate_and_add_block(b, block)
            if block.is_transaction_block():
                last_tx_block = block.header_hash
        peak = b.get_peak()
        assert peak is not None
        assert peak.height == reorg_point - 1
        assert maybe_header_hash(b.get_tx_peak()) == last_tx_block

        reorg_last_tx_block: Optional[bytes32] = None
        fork_block = blocks[9]
        fork_info = ForkInfo(fork_block.height, fork_block.height, fork_block.header_hash)
        blocks_reorg_chain = bt.get_consecutive_blocks(7, blocks[:10], seed=b"2")
        assert blocks_reorg_chain[reorg_point].is_transaction_block() is False
        for reorg_block in blocks_reorg_chain:
            if reorg_block.height < 10:
                await _validate_and_add_block(b, reorg_block, expected_result=AddBlockResult.ALREADY_HAVE_BLOCK)
            elif reorg_block.height < reorg_point:
                await _validate_and_add_block(
                    b, reorg_block, expected_result=AddBlockResult.ADDED_AS_ORPHAN, fork_info=fork_info
                )
            elif reorg_block.height >= reorg_point:
                await _validate_and_add_block(b, reorg_block, fork_info=fork_info)

            if reorg_block.is_transaction_block():
                reorg_last_tx_block = reorg_block.header_hash
            if reorg_block.height >= reorg_point:
                last_tx_block = reorg_last_tx_block

            assert maybe_header_hash(b.get_tx_peak()) == last_tx_block

        peak = b.get_peak()
        assert peak is not None
        assert peak.height == 16

    @pytest.mark.anyio
    @pytest.mark.parametrize("light_blocks", [True, False])
    async def test_long_reorg(
        self,
        light_blocks: bool,
        empty_blockchain: Blockchain,
        default_10000_blocks: list[FullBlock],
        test_long_reorg_blocks: list[FullBlock],
        test_long_reorg_blocks_light: list[FullBlock],
    ) -> None:
        if light_blocks:
            reorg_blocks = test_long_reorg_blocks_light[:1650]
        else:
            reorg_blocks = test_long_reorg_blocks[:1200]

        # Reorg longer than a difficulty adjustment
        # Also tests higher weight chain but lower height
        b = empty_blockchain
        num_blocks_chain_1 = 1600
        num_blocks_chain_2_start = 500

        assert num_blocks_chain_1 < 10000
        blocks = default_10000_blocks[:num_blocks_chain_1]

        print(f"pre-validating {len(blocks)} blocks")
        ssi = b.constants.SUB_SLOT_ITERS_STARTING
        diff = b.constants.DIFFICULTY_STARTING
        chain = AugmentedBlockchain(b)
        vs = ValidationState(ssi, diff, None)
        futures = []
        for block in blocks:
            futures.append(
                await pre_validate_block(
                    b.constants,
                    chain,
                    block,
                    b.pool,
                    None,
                    vs,
                )
            )
        pre_validation_results: list[PreValidationResult] = list(await asyncio.gather(*futures))
        for i, block in enumerate(blocks):
            if block.height != 0 and len(block.finished_sub_slots) > 0:
                if block.finished_sub_slots[0].challenge_chain.new_sub_slot_iters is not None:
                    ssi = block.finished_sub_slots[0].challenge_chain.new_sub_slot_iters
            assert pre_validation_results[i].error is None
            if (block.height % 100) == 0:
                print(f"main chain: {block.height:4} weight: {block.weight}")

            fork_info: ForkInfo = ForkInfo(block.height - 1, block.height - 1, block.prev_header_hash)
            assert fork_info is not None
            (result, err, _) = await b.add_block(
                block, pre_validation_results[i], sub_slot_iters=ssi, fork_info=fork_info
            )
            await check_block_store_invariant(b)
            assert err is None
            assert result == AddBlockResult.NEW_PEAK

        peak = b.get_peak()
        assert peak is not None
        chain_1_height = peak.height
        chain_1_weight = peak.weight
        assert chain_1_height == (num_blocks_chain_1 - 1)

        # The reorg blocks will have less time between them (timestamp) and therefore will make difficulty go up
        # This means that the weight will grow faster, and we can get a heavier chain with lower height

        # If these assert fail, you probably need to change the fixture in reorg_blocks to create the
        # right amount of blocks at the right time
        assert reorg_blocks[num_blocks_chain_2_start - 1] == default_10000_blocks[num_blocks_chain_2_start - 1]
        assert reorg_blocks[num_blocks_chain_2_start] != default_10000_blocks[num_blocks_chain_2_start]

        # one aspect of this test is to make sure we can reorg blocks that are
        # not in the cache. We need to explicitly prune the cache to get that
        # effect.
        b.clean_block_records()

        first_peak = b.get_peak()
        fork_info2 = None
        for reorg_block in reorg_blocks:
            if (reorg_block.height % 100) == 0:
                peak = b.get_peak()
                assert peak is not None
                print(
                    f"reorg chain: {reorg_block.height:4} "
                    f"weight: {reorg_block.weight:7} "
                    f"peak: {str(peak.header_hash)[:6]}"
                )

            if reorg_block.height < num_blocks_chain_2_start:
                await _validate_and_add_block(b, reorg_block, expected_result=AddBlockResult.ALREADY_HAVE_BLOCK)
            elif reorg_block.weight <= chain_1_weight:
                if fork_info2 is None:
                    fork_info2 = ForkInfo(reorg_block.height - 1, reorg_block.height - 1, reorg_block.prev_header_hash)
                await _validate_and_add_block(
                    b, reorg_block, expected_result=AddBlockResult.ADDED_AS_ORPHAN, fork_info=fork_info2
                )
            elif reorg_block.weight > chain_1_weight:
                await _validate_and_add_block(
                    b, reorg_block, expected_result=AddBlockResult.NEW_PEAK, fork_info=fork_info2
                )

        # if these asserts fires, there was no reorg
        peak = b.get_peak()
        assert peak is not None
        assert first_peak != peak
        assert peak is not None
        assert peak.weight > chain_1_weight
        second_peak = peak

        if light_blocks:
            assert peak.height > chain_1_height
        else:
            assert peak.height < chain_1_height

        chain_2_weight = peak.weight

        # now reorg back to the original chain
        # this exercises the case where we have some of the blocks in the DB already
        b.clean_block_records()

        if light_blocks:
            blocks = default_10000_blocks[num_blocks_chain_2_start - 100 : 1800]
        else:
            blocks = default_10000_blocks[num_blocks_chain_2_start - 100 : 2600]

        # the block validation requires previous block records to be in the
        # cache
        br = await b.get_block_record_from_db(blocks[0].prev_header_hash)
        for i in range(200):
            assert br is not None
            b.add_block_record(br)
            br = await b.get_block_record_from_db(br.prev_hash)
        assert br is not None
        b.add_block_record(br)

        # start the fork point a few blocks back, to test that the blockchain
        # can catch up
        fork_block = default_10000_blocks[num_blocks_chain_2_start - 101]
        fork_info = ForkInfo(fork_block.height, fork_block.height, fork_block.header_hash)
        await b.warmup(fork_block.height)
        for block in blocks:
            if (block.height % 128) == 0:
                peak = b.get_peak()
                assert peak is not None
                print(f"original chain: {block.height:4} weight: {block.weight:7} peak: {str(peak.header_hash)[:6]}")
            if block.height <= chain_1_height:
                expect = AddBlockResult.ALREADY_HAVE_BLOCK
            elif block.weight < chain_2_weight:
                expect = AddBlockResult.ADDED_AS_ORPHAN
            else:
                expect = AddBlockResult.NEW_PEAK
            await _validate_and_add_block(b, block, fork_info=fork_info, expected_result=expect)

        # if these asserts fires, there was no reorg back to the original chain
        peak = b.get_peak()
        assert peak is not None
        assert peak.header_hash != second_peak.header_hash
        assert peak.weight > chain_2_weight

    @pytest.mark.anyio
    async def test_long_compact_blockchain(
        self, empty_blockchain: Blockchain, default_2000_blocks_compact: list[FullBlock]
    ) -> None:
        b = empty_blockchain
        for block in default_2000_blocks_compact:
            await _validate_and_add_block(b, block, skip_prevalidation=True)
        peak = b.get_peak()
        assert peak is not None
        assert peak.height == len(default_2000_blocks_compact) - 1

    @pytest.mark.anyio
    async def test_reorg_from_genesis(self, empty_blockchain: Blockchain, bt: BlockTools) -> None:
        b = empty_blockchain

        blocks = bt.get_consecutive_blocks(15)

        for block in blocks:
            await _validate_and_add_block(b, block)
        peak = b.get_peak()
        assert peak is not None
        assert peak.height == 14

        # Reorg to alternate chain that is 1 height longer
        blocks_reorg_chain = bt.get_consecutive_blocks(16, [], seed=b"2")
        fork_info = ForkInfo(-1, -1, bt.constants.GENESIS_CHALLENGE)
        for reorg_block in blocks_reorg_chain:
            if reorg_block.height < 15:
                await _validate_and_add_block_multi_result(
                    b,
                    reorg_block,
                    expected_result=[AddBlockResult.ADDED_AS_ORPHAN, AddBlockResult.ALREADY_HAVE_BLOCK],
                    fork_info=fork_info,
                )
            elif reorg_block.height >= 15:
                await _validate_and_add_block(b, reorg_block, fork_info=fork_info)

        # Back to original chain
        blocks_reorg_chain_2 = bt.get_consecutive_blocks(3, blocks, seed=b"3")

        # we start from the beginning to make sure fork_info is built correctly
        fork_info = ForkInfo(-1, -1, bt.constants.GENESIS_CHALLENGE)
        for reorg_block in blocks_reorg_chain_2:
            if reorg_block.height < 15:
                await _validate_and_add_block(
                    b, reorg_block, expected_result=AddBlockResult.ALREADY_HAVE_BLOCK, fork_info=fork_info
                )
            elif reorg_block.height < 16:
                await _validate_and_add_block(
                    b, reorg_block, expected_result=AddBlockResult.ADDED_AS_ORPHAN, fork_info=fork_info
                )
            else:
                await _validate_and_add_block(b, reorg_block, fork_info=fork_info)

        peak = b.get_peak()
        assert peak is not None
        assert peak.height == 17

    @pytest.mark.anyio
    async def test_reorg_transaction(self, empty_blockchain: Blockchain, bt: BlockTools) -> None:
        b = empty_blockchain
        wallet_a = WalletTool(b.constants)
        WALLET_A_PUZZLE_HASHES = [wallet_a.get_new_puzzlehash() for _ in range(5)]
        coinbase_puzzlehash = WALLET_A_PUZZLE_HASHES[0]
        receiver_puzzlehash = WALLET_A_PUZZLE_HASHES[1]

        blocks = bt.get_consecutive_blocks(10, farmer_reward_puzzle_hash=coinbase_puzzlehash)
        blocks = bt.get_consecutive_blocks(
            2, blocks, farmer_reward_puzzle_hash=coinbase_puzzlehash, guarantee_transaction_block=True
        )

        spend_block = blocks[10]
        spend_coin = None
        for coin in spend_block.get_included_reward_coins():
            if coin.puzzle_hash == coinbase_puzzlehash:
                spend_coin = coin
        assert spend_coin is not None
        spend_bundle = wallet_a.generate_signed_transaction(uint64(1_000), receiver_puzzlehash, spend_coin)

        blocks = bt.get_consecutive_blocks(
            2,
            blocks,
            farmer_reward_puzzle_hash=coinbase_puzzlehash,
            transaction_data=spend_bundle,
            guarantee_transaction_block=True,
        )

        blocks_fork = bt.get_consecutive_blocks(
            1, blocks[:12], farmer_reward_puzzle_hash=coinbase_puzzlehash, seed=b"123", guarantee_transaction_block=True
        )
        blocks_fork = bt.get_consecutive_blocks(
            2,
            blocks_fork,
            farmer_reward_puzzle_hash=coinbase_puzzlehash,
            transaction_data=spend_bundle,
            guarantee_transaction_block=True,
            seed=b"1245",
        )
        for block in blocks:
            await _validate_and_add_block(b, block)
        fork_block = blocks[11]
        fork_info = ForkInfo(fork_block.height, fork_block.height, fork_block.header_hash)
        for block in blocks_fork[12:]:
            await _validate_and_add_block_no_error(b, block, fork_info=fork_info)

    @pytest.mark.anyio
    async def test_get_header_blocks_in_range_tx_filter(self, empty_blockchain: Blockchain, bt: BlockTools) -> None:
        b = empty_blockchain
        blocks = bt.get_consecutive_blocks(
            3,
            guarantee_transaction_block=True,
            pool_reward_puzzle_hash=bt.pool_ph,
            farmer_reward_puzzle_hash=bt.pool_ph,
        )
        await _validate_and_add_block(b, blocks[0])
        await _validate_and_add_block(b, blocks[1])
        await _validate_and_add_block(b, blocks[2])
        wt: WalletTool = bt.get_pool_wallet_tool()
        tx = wt.generate_signed_transaction(
            uint64(10), wt.get_new_puzzlehash(), blocks[2].get_included_reward_coins()[0]
        )
        blocks = bt.get_consecutive_blocks(
            1,
            block_list_input=blocks,
            guarantee_transaction_block=True,
            transaction_data=tx,
        )
        await _validate_and_add_block(b, blocks[-1])

        blocks_with_filter = await b.get_header_blocks_in_range(0, 10, tx_filter=True)
        blocks_without_filter = await b.get_header_blocks_in_range(0, 10, tx_filter=False)
        header_hash = blocks[-1].header_hash
        assert (
            blocks_with_filter[header_hash].transactions_filter
            != blocks_without_filter[header_hash].transactions_filter
        )
        assert blocks_with_filter[header_hash].header_hash == blocks_without_filter[header_hash].header_hash

    @pytest.mark.anyio
    async def test_get_blocks_at(self, empty_blockchain: Blockchain, default_1000_blocks: list[FullBlock]) -> None:
        b = empty_blockchain
        heights = []
        for block in default_1000_blocks[:200]:
            heights.append(block.height)
            await _validate_and_add_block(b, block)

        blocks = await b.get_block_records_at(heights)
        assert blocks
        assert len(blocks) == 200
        assert blocks[-1].height == 199

    @pytest.mark.anyio
    async def test_overlong_generator_encoding(
        self, empty_blockchain: Blockchain, bt: BlockTools, consensus_mode: ConsensusMode
    ) -> None:
        # add enough blocks to pass the hard fork
        blocks = bt.get_consecutive_blocks(10)
        for b in blocks[:-1]:
            await _validate_and_add_block(empty_blockchain, b)

        while not blocks[-1].is_transaction_block():
            await _validate_and_add_block(empty_blockchain, blocks[-1])
            blocks = bt.get_consecutive_blocks(1, block_list_input=blocks)
        original_block: FullBlock = blocks[-1]

        # overlong encoding
        generator = SerializedProgram.fromhex("c00101")
        assert not is_canonical_serialization(bytes(generator))

        block = recursive_replace(original_block, "transactions_generator", generator)
        block = recursive_replace(block, "transactions_info.generator_root", std_hash(bytes(generator)))
        block = recursive_replace(
            block, "foliage_transaction_block.transactions_info_hash", std_hash(bytes(block.transactions_info))
        )
        block = recursive_replace(
            block, "foliage.foliage_transaction_block_hash", std_hash(bytes(block.foliage_transaction_block))
        )

        # overlong encoding became invalid in the 3.0 hard fork
        if consensus_mode == ConsensusMode.HARD_FORK_3_0:
            expected_error = Err.INVALID_TRANSACTIONS_GENERATOR_ENCODING
        else:
            expected_error = None

        await _validate_and_add_block(empty_blockchain, block, expected_error=expected_error, skip_prevalidation=True)


@pytest.mark.anyio
async def test_reorg_new_ref(empty_blockchain: Blockchain, bt: BlockTools) -> None:
    b = empty_blockchain
    wallet_a = WalletTool(b.constants)
    WALLET_A_PUZZLE_HASHES = [wallet_a.get_new_puzzlehash() for _ in range(5)]
    coinbase_puzzlehash = WALLET_A_PUZZLE_HASHES[0]
    receiver_puzzlehash = WALLET_A_PUZZLE_HASHES[1]

    blocks = bt.get_consecutive_blocks(
        5,
        farmer_reward_puzzle_hash=coinbase_puzzlehash,
        pool_reward_puzzle_hash=receiver_puzzlehash,
        guarantee_transaction_block=True,
    )

    all_coins = []
    for spend_block in blocks[:5]:
        for coin in spend_block.get_included_reward_coins():
            if coin.puzzle_hash == coinbase_puzzlehash:
                all_coins.append(coin)
    spend_bundle_0 = wallet_a.generate_signed_transaction(uint64(1_000), receiver_puzzlehash, all_coins.pop())
    blocks = bt.get_consecutive_blocks(
        15,
        block_list_input=blocks,
        farmer_reward_puzzle_hash=coinbase_puzzlehash,
        pool_reward_puzzle_hash=receiver_puzzlehash,
        transaction_data=spend_bundle_0,
        guarantee_transaction_block=True,
    )

    for block in blocks:
        await _validate_and_add_block(b, block)
    peak = b.get_peak()
    assert peak is not None
    assert peak.height == 19

    print("first chain done")

    # Make sure a ref back into the reorg chain itself works as expected

    blocks_reorg_chain = bt.get_consecutive_blocks(
        1,
        blocks[:10],
        seed=b"2",
        farmer_reward_puzzle_hash=coinbase_puzzlehash,
        pool_reward_puzzle_hash=receiver_puzzlehash,
    )
    spend_bundle = wallet_a.generate_signed_transaction(uint64(1_000), receiver_puzzlehash, all_coins.pop())

    blocks_reorg_chain = bt.get_consecutive_blocks(
        2,
        blocks_reorg_chain,
        seed=b"2",
        farmer_reward_puzzle_hash=coinbase_puzzlehash,
        pool_reward_puzzle_hash=receiver_puzzlehash,
        transaction_data=spend_bundle,
        guarantee_transaction_block=True,
    )

    spend_bundle2 = wallet_a.generate_signed_transaction(uint64(1_000), receiver_puzzlehash, all_coins.pop())
    blocks_reorg_chain = bt.get_consecutive_blocks(
        4, blocks_reorg_chain, seed=b"2", block_refs=[uint32(5), uint32(11)], transaction_data=spend_bundle2
    )
    blocks_reorg_chain = bt.get_consecutive_blocks(4, blocks_reorg_chain, seed=b"2")

    fork_info = ForkInfo(-1, -1, b.constants.GENESIS_CHALLENGE)
    for i, block in enumerate(blocks_reorg_chain):
        if i < 10:
            expected = AddBlockResult.ALREADY_HAVE_BLOCK
        elif i < 19:
            expected = AddBlockResult.ADDED_AS_ORPHAN
        elif i == 19:
            # same height as peak decide by iterations
            peak = b.get_peak()
            assert peak is not None
            # same height as peak should be ADDED_AS_ORPHAN if  block.total_iters >= peak.total_iters
            assert block.total_iters < peak.total_iters
            expected = AddBlockResult.NEW_PEAK
        else:
            expected = AddBlockResult.NEW_PEAK
        await _validate_and_add_block(b, block, expected_result=expected, fork_info=fork_info)
    peak = b.get_peak()
    assert peak is not None
    assert peak.height == 20


# this test doesn't reorg, but _reconsider_peak() is passed a stale
# "fork_height" to make it look like it's in a reorg, but all the same blocks
# are just added back.
@pytest.mark.anyio
async def test_reorg_stale_fork_height(empty_blockchain: Blockchain, bt: BlockTools) -> None:
    b = empty_blockchain
    wallet_a = WalletTool(b.constants)
    WALLET_A_PUZZLE_HASHES = [wallet_a.get_new_puzzlehash() for _ in range(5)]
    coinbase_puzzlehash = WALLET_A_PUZZLE_HASHES[0]
    receiver_puzzlehash = WALLET_A_PUZZLE_HASHES[1]

    blocks = bt.get_consecutive_blocks(
        5,
        farmer_reward_puzzle_hash=coinbase_puzzlehash,
        pool_reward_puzzle_hash=receiver_puzzlehash,
        guarantee_transaction_block=True,
    )

    all_coins = []
    for spend_block in blocks:
        for coin in spend_block.get_included_reward_coins():
            if coin.puzzle_hash == coinbase_puzzlehash:
                all_coins.append(coin)

    # Make sure a ref back into the reorg chain itself works as expected
    spend_bundle = wallet_a.generate_signed_transaction(uint64(1_000), receiver_puzzlehash, all_coins.pop())

    # make sure we have a transaction block, with at least one transaction in it
    blocks = bt.get_consecutive_blocks(
        5,
        blocks,
        farmer_reward_puzzle_hash=coinbase_puzzlehash,
        pool_reward_puzzle_hash=receiver_puzzlehash,
        transaction_data=spend_bundle,
        guarantee_transaction_block=True,
    )

    # this block (height 10) refers back to the generator in block 5
    spend_bundle2 = wallet_a.generate_signed_transaction(uint64(1_000), receiver_puzzlehash, all_coins.pop())
    blocks = bt.get_consecutive_blocks(4, blocks, block_refs=[uint32(5)], transaction_data=spend_bundle2)

    for block in blocks[:5]:
        await _validate_and_add_block(b, block, expected_result=AddBlockResult.NEW_PEAK)

    # fake the fork_info to make every new block look like a reorg
    fork_info = ForkInfo(blocks[4].height, blocks[4].height, blocks[4].header_hash)
    for block in blocks[5:]:
        await _validate_and_add_block(b, block, expected_result=AddBlockResult.NEW_PEAK, fork_info=fork_info)
    peak = b.get_peak()
    assert peak is not None
    assert peak.height == 13


@pytest.mark.anyio
async def test_chain_failed_rollback(empty_blockchain: Blockchain, bt: BlockTools) -> None:
    b = empty_blockchain
    wallet_a = WalletTool(b.constants)
    WALLET_A_PUZZLE_HASHES = [wallet_a.get_new_puzzlehash() for _ in range(5)]
    coinbase_puzzlehash = WALLET_A_PUZZLE_HASHES[0]
    receiver_puzzlehash = WALLET_A_PUZZLE_HASHES[1]

    blocks = bt.get_consecutive_blocks(
        20,
        farmer_reward_puzzle_hash=coinbase_puzzlehash,
        pool_reward_puzzle_hash=receiver_puzzlehash,
    )

    for block in blocks:
        await _validate_and_add_block(b, block)
    peak = b.get_peak()
    assert peak is not None
    assert peak.height == 19

    print("first chain done")

    # Make sure a ref back into the reorg chain itself works as expected

    all_coins = []
    for spend_block in blocks[:10]:
        for coin in spend_block.get_included_reward_coins():
            if coin.puzzle_hash == coinbase_puzzlehash:
                all_coins.append(coin)

    spend_bundle = wallet_a.generate_signed_transaction(uint64(1_000), receiver_puzzlehash, all_coins.pop())

    blocks_reorg_chain = bt.get_consecutive_blocks(
        11,
        blocks[:10],
        seed=b"2",
        farmer_reward_puzzle_hash=coinbase_puzzlehash,
        pool_reward_puzzle_hash=receiver_puzzlehash,
        transaction_data=spend_bundle,
        guarantee_transaction_block=True,
    )

    fork_block = blocks_reorg_chain[9]
    fork_info = ForkInfo(fork_block.height, fork_block.height, fork_block.header_hash)
    for block in blocks_reorg_chain[10:-1]:
        await _validate_and_add_block(b, block, expected_result=AddBlockResult.ADDED_AS_ORPHAN, fork_info=fork_info)

    # Incorrectly set the height as spent in DB to trigger an error
    print(f"{await b.coin_store.get_coin_record(spend_bundle.coin_spends[0].coin.name())}")
    print(spend_bundle.coin_spends[0].coin.name())
    # await b.coin_store._set_spent([spend_bundle.coin_spends[0].coin.name()], 8)
    await b.coin_store.rollback_to_block(2)
    print(f"{await b.coin_store.get_coin_record(spend_bundle.coin_spends[0].coin.name())}")

    fork_block = blocks_reorg_chain[10 - 1]
    # fork_info = ForkInfo(fork_block.height, fork_block.height, fork_block.header_hash)
    with pytest.raises(ValueError, match="Invalid operation to set spent"):
        await _validate_and_add_block(b, blocks_reorg_chain[-1], fork_info=fork_info)

    peak = b.get_peak()
    assert peak is not None
    assert peak.height == 19


@pytest.mark.anyio
async def test_reorg_flip_flop(empty_blockchain: Blockchain, bt: BlockTools) -> None:
    b = empty_blockchain
    wallet_a = WalletTool(b.constants)
    WALLET_A_PUZZLE_HASHES = [wallet_a.get_new_puzzlehash() for _ in range(5)]
    coinbase_puzzlehash = WALLET_A_PUZZLE_HASHES[0]
    receiver_puzzlehash = WALLET_A_PUZZLE_HASHES[1]

    chain_a = bt.get_consecutive_blocks(
        10,
        farmer_reward_puzzle_hash=coinbase_puzzlehash,
        pool_reward_puzzle_hash=receiver_puzzlehash,
        guarantee_transaction_block=True,
    )

    all_coins = []
    for spend_block in chain_a:
        for coin in spend_block.get_included_reward_coins():
            if coin.puzzle_hash == coinbase_puzzlehash:
                all_coins.append(coin)

    # this is a transaction block at height 10
    spend_bundle = wallet_a.generate_signed_transaction(uint64(1_000), receiver_puzzlehash, all_coins.pop())
    chain_a = bt.get_consecutive_blocks(
        5,
        chain_a,
        farmer_reward_puzzle_hash=coinbase_puzzlehash,
        pool_reward_puzzle_hash=receiver_puzzlehash,
        transaction_data=spend_bundle,
        guarantee_transaction_block=True,
    )

    spend_bundle = wallet_a.generate_signed_transaction(uint64(1_000), receiver_puzzlehash, all_coins.pop())
    chain_a = bt.get_consecutive_blocks(
        5,
        chain_a,
        block_refs=[uint32(10)],
        transaction_data=spend_bundle,
        guarantee_transaction_block=True,
    )

    spend_bundle = wallet_a.generate_signed_transaction(uint64(1_000), receiver_puzzlehash, all_coins.pop())
    chain_a = bt.get_consecutive_blocks(
        20,
        chain_a,
        farmer_reward_puzzle_hash=coinbase_puzzlehash,
        pool_reward_puzzle_hash=receiver_puzzlehash,
        transaction_data=spend_bundle,
        guarantee_transaction_block=True,
    )

    # chain A is 40 blocks deep
    # chain B share the first 20 blocks with chain A

    # add 5 blocks on top of the first 20, to form chain B
    chain_b = bt.get_consecutive_blocks(
        5,
        chain_a[:20],
        seed=b"2",
        farmer_reward_puzzle_hash=coinbase_puzzlehash,
        pool_reward_puzzle_hash=receiver_puzzlehash,
    )
    spend_bundle = wallet_a.generate_signed_transaction(uint64(1_000), receiver_puzzlehash, all_coins.pop())

    # this is a transaction block at height 15 (in Chain B)
    chain_b = bt.get_consecutive_blocks(
        5,
        chain_b,
        seed=b"2",
        farmer_reward_puzzle_hash=coinbase_puzzlehash,
        pool_reward_puzzle_hash=receiver_puzzlehash,
        transaction_data=spend_bundle,
        guarantee_transaction_block=True,
    )

    spend_bundle = wallet_a.generate_signed_transaction(uint64(1_000), receiver_puzzlehash, all_coins.pop())
    chain_b = bt.get_consecutive_blocks(10, chain_b, seed=b"2", block_refs=[uint32(15)], transaction_data=spend_bundle)

    assert len(chain_a) == len(chain_b)

    counter = 0
    ssi = b.constants.SUB_SLOT_ITERS_STARTING
    diff = b.constants.DIFFICULTY_STARTING
    for b1, b2 in zip(chain_a, chain_b):
        # alternate the order we add blocks from the two chains, to ensure one
        # chain overtakes the other one in weight every other time
        if counter % 2 == 0:
            block1, block2 = b2, b1
        else:
            block1, block2 = b1, b2
        counter += 1

        preval = await (
            await pre_validate_block(
                b.constants,
                AugmentedBlockchain(b),
                block1,
                b.pool,
                None,
                ValidationState(ssi, diff, None),
            )
        )
        peak = b.get_peak()
        if peak is None:
            fork_info = ForkInfo(-1, -1, bt.constants.GENESIS_CHALLENGE)
        else:
            fork_info = await get_fork_info(b, block1, peak)
        _, err, _ = await b.add_block(block1, preval, sub_slot_iters=ssi, fork_info=fork_info)
        assert err is None
        preval = await (
            await pre_validate_block(
                b.constants,
                AugmentedBlockchain(b),
                block2,
                b.pool,
                None,
                ValidationState(ssi, diff, None),
            )
        )
        peak = b.get_peak()
        assert peak is not None
        fork_info = await get_fork_info(b, block2, peak)
        _, err, _ = await b.add_block(block2, preval, sub_slot_iters=ssi, fork_info=fork_info)
        assert err is None

    peak = b.get_peak()
    assert peak is not None
    assert peak.height == 39

    chain_b = bt.get_consecutive_blocks(
        10,
        chain_b,
        seed=b"2",
        farmer_reward_puzzle_hash=coinbase_puzzlehash,
        pool_reward_puzzle_hash=receiver_puzzlehash,
    )

    for block in chain_b[40:]:
        await _validate_and_add_block(b, block)


async def test_get_tx_peak(default_400_blocks: list[FullBlock], empty_blockchain: Blockchain) -> None:
    bc = empty_blockchain
    test_blocks = default_400_blocks[:100]
    ssi = bc.constants.SUB_SLOT_ITERS_STARTING
    diff = bc.constants.DIFFICULTY_STARTING
    futures: list[Awaitable[PreValidationResult]] = []
    chain = AugmentedBlockchain(bc)
    vs = ValidationState(ssi, diff, None)
    for block in test_blocks:
        futures.append(
            await pre_validate_block(
                bc.constants,
                chain,
                block,
                bc.pool,
                None,
                vs,
            )
        )

    res: list[PreValidationResult] = list(await asyncio.gather(*futures))

    last_tx_block_record = None
    for b, prevalidation_res in zip(test_blocks, res):
        assert bc.get_tx_peak() == last_tx_block_record
        fork_info = ForkInfo(b.height - 1, b.height - 1, b.prev_header_hash)
        _, err, _ = await bc.add_block(b, prevalidation_res, sub_slot_iters=ssi, fork_info=fork_info)
        assert err is None

        if b.is_transaction_block():
            assert prevalidation_res.required_iters is not None
            block_record = block_to_block_record(
                bc.constants,
                bc,
                prevalidation_res.required_iters,
                b,
                empty_blockchain.constants.SUB_SLOT_ITERS_STARTING,
            )
            last_tx_block_record = block_record

    assert bc.get_tx_peak() == last_tx_block_record


def to_bytes(gen: Optional[SerializedProgram]) -> bytes:
    assert gen is not None
    return bytes(gen)


@pytest.mark.anyio
@pytest.mark.limit_consensus_modes(reason="block heights for generators differ between test chains in different modes")
@pytest.mark.parametrize("clear_cache", [True, False])
async def test_lookup_block_generators(
    default_10000_blocks: list[FullBlock],
    test_long_reorg_blocks_light: list[FullBlock],
    bt: BlockTools,
    empty_blockchain: Blockchain,
    clear_cache: bool,
) -> None:
    b = empty_blockchain
    blocks_1 = default_10000_blocks
    blocks_2 = test_long_reorg_blocks_light

    # this test blockchain is expected to have block generators at these
    # heights:
    # 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,
    # 24, 25, 26, 28

    # default_10000_blocks and test_long_reorg_blocks_light diverge at height
    # 500. Add blocks from both past the fork to be able to test both

    # fork 1 is expected to have generators at these heights:
    # 503, 507, 511, 517, 524, 529, 532, 533, 534, 539, 542, 543, 546, 547

    # fork 2 is expected to have generators at these heights:
    # 507, 516, 527, 535, 539, 543, 547

    # start with adding some blocks to test lookups from the mainchain
    fork_info = ForkInfo(-1, -1, bt.constants.GENESIS_CHALLENGE)
    for block in blocks_2[:550]:
        await _validate_and_add_block(b, block, expected_result=AddBlockResult.NEW_PEAK, fork_info=fork_info)

    fork_info = ForkInfo(blocks_1[500].height - 1, blocks_1[500].height - 1, blocks_1[500].prev_header_hash)
    for block in blocks_1[500:550]:
        await _validate_and_add_block(b, block, expected_result=AddBlockResult.ADDED_AS_ORPHAN, fork_info=fork_info)

    # now we have a blockchain with two forks, the peak is at blocks_2[550] and
    # the leight weight peak is at blocks_1[550]
    # make sure we can lookup block generators from each fork

    peak_1 = blocks_1[550]
    peak_2 = blocks_2[550]

    # single generators, from the shared part of the chain
    for peak in [peak_1, peak_2]:
        if clear_cache:
            b.clean_block_records()
        generators = await b.lookup_block_generators(peak.prev_header_hash, {uint32(2)})
        assert generators == {
            uint32(2): to_bytes(blocks_1[2].transactions_generator),
        }

    # multiple generators from the shared part of the chain
    for peak in [peak_1, peak_2]:
        if clear_cache:
            b.clean_block_records()
        generators = await b.lookup_block_generators(peak.prev_header_hash, {uint32(2), uint32(10), uint32(26)})
        assert generators == {
            uint32(2): to_bytes(blocks_1[2].transactions_generator),
            uint32(10): to_bytes(blocks_1[10].transactions_generator),
            uint32(26): to_bytes(blocks_1[26].transactions_generator),
        }

    # lookups from the past the fork
    if clear_cache:
        b.clean_block_records()
    generators = await b.lookup_block_generators(peak_1.prev_header_hash, {uint32(503)})
    assert generators == {uint32(503): to_bytes(blocks_1[503].transactions_generator)}

    if clear_cache:
        b.clean_block_records()
    generators = await b.lookup_block_generators(peak_2.prev_header_hash, {uint32(516)})
    assert generators == {uint32(516): to_bytes(blocks_2[516].transactions_generator)}

    # make sure we don't cross the forks
    if clear_cache:
        b.clean_block_records()
    with pytest.raises(ValueError, match=re.escape(Err.GENERATOR_REF_HAS_NO_GENERATOR.name)):
        await b.lookup_block_generators(peak_1.prev_header_hash, {uint32(516)})

    if clear_cache:
        b.clean_block_records()
    with pytest.raises(ValueError, match=re.escape(Err.GENERATOR_REF_HAS_NO_GENERATOR.name)):
        await b.lookup_block_generators(peak_2.prev_header_hash, {uint32(503)})

    # make sure we fail when looking up a non-transaction block from the main
    # chain, regardless of which chain we start at
    if clear_cache:
        b.clean_block_records()
    with pytest.raises(ValueError, match=re.escape(Err.GENERATOR_REF_HAS_NO_GENERATOR.name)):
        await b.lookup_block_generators(peak_1.prev_header_hash, {uint32(8)})

    if clear_cache:
        b.clean_block_records()
    with pytest.raises(ValueError, match=re.escape(Err.GENERATOR_REF_HAS_NO_GENERATOR.name)):
        await b.lookup_block_generators(peak_2.prev_header_hash, {uint32(8)})

    # if we try to look up generators starting from a disconnected block, we
  